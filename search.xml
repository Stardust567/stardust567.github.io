<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[恋与L]]></title>
    <url>%2F2019%2F02%2F14%2F%E6%81%8BL%2F</url>
    <content type="text"><![CDATA[第一章&emsp;&emsp;初遇L是在我中考后的那个暑假，那时候不知道是哪里来的好学之心，竟然去报了个初升高的衔接班。爸妈看我这么有志气的样子感觉也没什么太正当的理由来阻拦我，就顺着我的意交钱让我上了。当然后来我高考完再寻思这事（其实我真正寻思这事是在高一，那时候内心疯狂吐槽为什么不好好过个没作业的假期）真真切切觉得这事儿除了能提高你点自信心外好像就真的没什么用处。刚到个陌生环境大家都不太适应，但是你竟然把前几个月要学的东西草草学了一遍，哎这你就有了一个能吹水，哦不，是能提高自信的机会了，当然这事也是因人而异，可能我会这么想多半是因为我天赋有限，白白糟蹋了钱财和大好的假期机会。&emsp;&emsp;在那个衔接班上，坐在我前面的就是L。这里给L取个名字吧，随意一点取的话，就叫路嘉琪吧。（虽然我说是很随意，但其实还是经历过某种深思熟虑的，绝对不是因为输入法蹦出来就随便选了这么草率的，嗯）第一次见她就觉着这个女孩子的发质非常好（？？？我绝对没有什么特殊的恋发癖），当然这并不是在给我上课卷她头发找借口，只是陈述一下第一眼的直观感受。她那时扎了个干净利索的马尾，但长度绝对能自然垂到肩下，发量很足，长发在末梢倒不显散乱。稍显弧度的马尾下是张非常白净的脸，记忆里是种瓷白，像玉石的温润中透着股月牙的皙白，如果能轻轻戳一下的话，说不定会是凉凉的瓷器手感。标准的杏脸加上不错的五官，再配上她显出的那种富养大小姐的感觉，大方里流露点江南水乡蕴出来的温婉味道，第一印象实在是不错。&emsp;&emsp;过了一开始的新奇劲儿，之后大家平常的介绍然后熟识，像这种衔接班也就上个一个月左右。这一个月的日子像是平时，只是换了批老师和同学，平日里该笑该闹还是继续。依稀记得上课的那个学校里栽了很多竹子，一节节地蹿上了好几层楼，视线偏转一下就能看见一墙又一墙的爬山虎，风吹的时候一层层地撩在人心上直痒痒。等熬到下课，我一般会去走廊上摘几片够得到的竹叶，上课了就把弄着竹叶玩儿，顺便留一片别在路嘉琪的马尾上。这种情况一般是不会被发现的，毕竟我的手法愈趋娴熟，而她的发量又着实比较充足。但人生在世总会遇到些说不清道不明的意外，偶尔被发现后她也只会回过头瞪着我几秒，毕竟我算准了上课时间她也不能做出什么过激的举动，等下课了，大家也就忘了这事儿，还像以往那样随意地谈天说地，聊着各种奇奇怪怪的话题。而随着这个衔接班的结束，中考录取结果也下来了，我和她不在同一所高中，她被我高中所谓的兄弟学校（我一直很好奇为什么不叫姐妹花学校）录取了。当时一边在心里小声哼着“啊~好朋友，再见~再见”一边做着不深不浅的道别，只是想着大概是没什么机会再见了，咱们，山高路远，就此别过。浑然不知后面还会和路嘉琪再扯上点意料之外的事。 第二章&emsp;&emsp;刚踏入高中校园的我有点点激动，这个高中很符合我的设想。整个校园很大（和我大二所在的校区一样大）各种徽派的设计也很得体，那股单纯的兴奋劲儿比我刚进大学校园还要冲（第四声）还要足。虽然高中是寄宿制，但大部分学生还是会选择走读即只中午在校午休。寝室是个标准六人间的配置，一般只会住四个人左右不会住满。最初的室友有三个人，名字也随意点，分别是大鲍、涵姐和骚翔。简单介绍下，大鲍是个身材魁梧，肤色偏黑，沉默寡言的壮硕男生，为人老实，热爱看书。平时不多言，但出口必能把我们骚到。涵姐整个人就有些浪里滑条的感觉，平时虽然骚浪了一点，但人却不差。除了那张浪里浪气的脸，各方面也是均值往上跑了。骚翔人如其名，一个“骚”字，论骚我也认识了不少人，但至今没人能骚得过他，以至于给我幼小的纯洁心灵留下了一道道崩坏三观的印子。骚翔看上去就像个新疆的混血，是偏烤羊肉串的那种，不过到底是哪一族的混血他不愿主动说，我们也不好意思问，这个问题便就此作罢，只能在心中随意想想。当熟悉了我这三位室友的作风，不禁仰头长叹，本来一个正值大好年华的青葱少年，却被命运给安排上了这三个明骚暗骚的人，也不知是福是祸，总之就这样展开了我第一段激情四射的宿舍生活。就比如军训的时候，作为一名纯洁正直，不蔓不枝的男子高中生，午休期间我肯定是不愿和他们三个同流合污相互扯淡的，那么睡觉无疑是我可以选择的最佳回避方式。但谁料，哪怕我睡了也无法暂停他们恶魔般的骚气步伐。涵姐见我侧卧在床半天没有动静，“你这不会就睡觉了吧？”，见我毫无回应之后索性放开了连念我名字后两字数十遍，想来大概和某种复杂的传教索魂仪式相似，嗯“我喊你声你敢应吗”的那种。“咦？”只见涵姐俯卧在床摸了摸自己的脸颊“这喊多了就成‘学姐’了，以后就叫学姐好吧”。其余两人略一思索，不约而同地觉得这个称呼十分贴切，真真是一场美妙的缘分，呃不是，室友情。就这样，我在睡梦中就有了这个贯穿我高中直至现在的外号。这声“学姐”被各式各样的人吐槽调侃过，像同学朋友就不说了，被班主任和各科老师，父母和亲戚……他们发现的来源主要有以下几种：在校几乎所有学生都喊我“学姐”不论男女（微笑脸）上课总会有人嘴贱喊出声叫老师听见，就像自己只是喝了口水般理所理当（微笑脸X2）网上评论直接“学姐”来“学姐”去，我爸妈真的想不知道都难（微笑脸X3）就这样慢慢的，“学姐”这个称号已经完美融入到我的人设里，成为了我生命中不可或缺的一份子（微笑脸X4）。&emsp;&emsp;正式上课后，我和那么多在题海里沉浮的少男少女并没什么二异，一个没什么太大爱好也没什么太多想法的的高一学生，整天就像被洗脑般脑中只有个高考的模糊影子，然后告诉你照着这个影子疯狂追就完事了，但丝毫没有人来告诉你追到了后要干什么，也没人告诉你这个影子后面会有那么多更加张牙舞爪的影子要你一个人去独自面对。不过嘛，那个时候的我们是没那个心思去思虑未来的，每天只顾着和周边人扯淡，关心些乱七八糟的事，以及在杂乱的烦心之余尽力学习一下意思意思。就在这样的肆意挥发荷尔蒙，哦不是，是散发青春气息的步子里，我跌跌撞撞地走了一个学期，谈不上多开心但整个生活确是像色调明亮的油画般充满了少年气，好似有股糯黄的酥糖味。而就在这个中二的骑士想要翻开下一学期的日历前，因为一件小事儿，路嘉琪找到了我。 第三章&emsp;&emsp;是件很小的事，但是借此为契机，我和她在网上慢慢熟络，渐渐抛开原先有的那点小拘谨，好感像颗种子在我尚未察觉之际已经慢慢吐出嫩绿的幼芽。我们从原来的如果什么时候在线就随便聊聊（事实上她的QQ显示是全天在线的，至少每次不论我什么时候上线她都一定是在的）到每天固定的些时间点互相聊些什么，一般是我听她说，然后我可能会给出些不温不火的建议与想法。啧现在想想我那个时候的回答应该可傻逼了，不过好在她应该只是想找个人可以安安静静地听她的各种烦忧，所以在这样的网聊节奏下，我和她的关系倒是越走越近，至少在我看来是更近些的。近到或者让我自以为是到，每天会不经意说出和她的聊天而觉得平常，这样的结果就是激起了我前座的狗血八卦之魂。我前座小黑是个偏瘦的女生，叫她小黑纯粹是因为她肤色偏黑一点，就这么随口叫下来了。小黑是那种人前疯来跑去，但内里有点忧郁寡淡，有时候还敏感事多的那种。不过她学了那么多年的舞，身材和气质还是有的。我这么帮她说话起源得归咎她给我的那张贺卡，那时候刚高中没什么事儿的孩子总喜欢互赠各种贺卡，别人的贺卡大都是些无关疼痒但微微暖心的小祝福，小黑的偏是什么“我也很喜欢纳兰容若的词”和“你平时都是笑的样子只是表面”这样的话，事实证明，千万不要和中二病说这些，如果你不想和他们扯上关系的话。这些话对中二病的杀伤力无疑是巨大的，所以之后关于她的事，初印象总还不错。她就追问了我路嘉琪的名字，然后诡异的事发生了，路嘉琪是小黑的初中闺蜜……嗯？？？这是什么神仙孽缘，啊不是，肯定是天造地设的缘分啊这次。&emsp;&emsp;就这样，白天找小黑聊着路嘉琪初中的事，晚上和路嘉琪随意地谈天说地，聊人生聊理想，当时只觉得日子过得像神仙一样，管他的高考学习，我只要能每天都和她聊上天就好了，再说我成绩也，也还行嘛，这种事情也肯定不会影响学习的啦。每天晚上找父母借到手机就往卫生间跑，用各种什么拉肚子啊泡澡怎么可能没有bgm这样的烂理由延长用手机的时间来和她聊天。 她发“我来当你的树洞好了，有什么话都可以对我说哦”， 我回“嗯嗯，你也是，有什么事情都直接和我说好了”。 “你想考什么学校啊”， “我啊，没怎么想过，应该是像北航这样的学校吧”。 “那很好啊”， “你呢？”。 “我想去上海或者江浙那边的学校，具体还没想好”， “不急，才高一嘛，像我想好了估计也考不上，北航好像挺难考的”。 “你可是学霸啊，要好好加油啊”， “嗯嗯，一定，你也是！”。 …… &emsp;&emsp;就这样，每晚我都躲在卫生间里偷着乐，现在想想，一个小男孩背靠着厕所的墙壁蹲在地上抱着宛若至宝的手机，看着屏幕上的字傻笑却不敢发出声的样子，真的是多亏了爸妈给我的无限信任。不过有点，和路嘉琪聊天的时候也不是没说过小黑的事，但她的回应就比较平淡了，和我想的有点不太一样，不过当时的我也没多想就继续乐呵着和她扯别的话题了。 第四章&emsp;&emsp;某个下午体育课我在操场问起小黑，“她的话应该比较受欢迎吧，初中有谈过恋爱吗？”，“嗯有”，“哎哎，是什么样的啊”，“嗯，她初中会经常性地用小刀割腕，留下了很多印子”，“？？？啊？”，小黑看了眼惊诧非常的我，淡淡地说“我觉得你看到的她只是很表面的她”小黑说完轻叹口气，撇过头继续回我的问题，“然后她的男朋友在她某次想用小刀划自己的时候，把刀抢过对着自己的手腕划了一刀，和她说以后如果再想割的话，我陪你一起割。她好像挺感动的，后来就在一起了。不过中考后发生了些事情，好像分手了，她也删掉了初中所有人的联系方式。”，“……”当时我有点说不出话来，所有的气力都卡在喉咙里发不出一点声音。我到现在为止的生活都很普通，普通地学习，普通地长大，普通地在老师父母设置好的轨迹上咕噜咕噜滚着。这样普通的我不能理解为什么会真的有人会选择自残，去尝试割腕。这对我的冲击一如多年后当我得知，有某个我很钦佩的很优秀的朋友选择用自杀结束自己年轻的生命和未知的前途的时候，从未想过这样的事会发生在自己的身边，所以当发生的时候所带来的冲击和动摇无疑是巨大的。小黑看我良久不说话，偏头看向我，“学姐，我觉得你做不到”，“为什么要选择和她一起割啊，不应该想办法让她不再伤害自己才对吗”我有点激动，夹着猝不及防的三观动摇，对她的心疼，还有自己的不服气。小黑回过头确是又叹了口气，“唉，所以你……不过或许你这样理想主义的真的能帮到她也不一定”，不过我当时的想法倒是：为什么你老是在叹气啊喂，我有那么不行吗喂。有些沮丧的我伸着头望了望周围，柔和偏橘的阳光打下来，整个操场以及操场上的人都好像被浇了层薄蜜，稍微有点闪，我下意识低了低头。“你喜欢她吗？”耳边突然传来小黑的声音，我有点慌乱，“啊？我不知道，应该没有吧，只是朋友而已，比较好的朋友而已”，“那如果她和别的男生走在一起，拥抱打kiss，你也不会难受？”，“可能会有一点吧，但……”小黑不等我说完就走开了，只留下一句“你慢慢想吧”，剩我一个呆呆站在操场上。慢慢想？我想个鬼啊，这种事我怎么知道。&emsp;&emsp;当晚，我还是和路嘉琪没心没肺地聊着天，只是在心里暗暗下决定，一定要帮她。（当时真的就是这么想的啊，现在想想人家根本就没什么好要我帮的，倒不如说每天聊聊天就已经很好了，但那个时候中二的我，嗯，总喜欢一厢情愿地沉浸在自己的想象里）第二天小黑倒也没再提那事，只是对我来说始终有个刺大大咧咧地刺在那儿。中午回到寝室，室友们正在用他们扯淡的想象展现着大鲍家是多么有钱，比如 “哎以后去当大鲍家的扫地嘚~给你配几把黄金镶钻扫把”，“啧，镶钻怎么配得上大鲍的身价，那肯定要全是钻石打造的才行”，“噢~这是我考虑不周了，再配个钻石拖把，拖出来的地那是要比钻石还要亮”……之后骚翔见我进来不说话，“哦豁，学姐你竟然不说话，是不是看不起大鲍的家产，你看你头顶马上就会有无数个红点”。我的内心：兄弟我正在思考一些很哲学，呃不，是很重要的问题，你这样我很跳戏啊喂。等我翻身爬上床后，大鲍看我靠墙的背影说“你们看学姐这个角度看好像个女生啊”，骚翔马上就接“学姐本来不就是个女生嘛”，在我刚想反驳的时候，我就看见涵姐直接过来一边爬我的梯子一边淫笑着“嘿嘿嘿那我们来确认一下不就好了”，骚翔看到后不甘示弱，因为我和他床在同一边，他在尝试着能不能直接跨过来……接下来，虽然我奋力抵抗，但终究是腹背受敌最后败下阵来。然后那天中午我们三个男生（大鲍还是比较好的，安安心心睡在自己床上）挤在一张小小寝室单人床里，竟然各自都睡着了，让我感受到了我高中宿舍床板质量之高。不过和他们这么闹过之后，心情倒是放开了很多。跟着楼梯和人流向上走的时候，我决定向路嘉琪表明自己的心意。 尾声&emsp;&emsp;这是个中二病一厢情愿最后什么也没能做到的故事。没能让她变得开心一点，不仅什么都做不到还给她徒增了很多烦闷。对当时的我来说，尽力想去帮别人但最后适得其反，给了我很深的打击，加上之前三观上的动摇，我开始对我本应普通的生活产生了怀疑。看着自己还未开出花朵的幼苗灰败地枯死，像是游荡到了某条寂静没有生灵的河流之中，随着水波慢慢浮沉。但哪怕心里难受得只想缩成一团藏进角落，还是有些回忆像荧星点点悬浮在脑海中，不忍让它们散去。在你触碰到美好的时候就应该想到，任何事情都不可能只有美好。此时的欢愉和彼时的苦痛不断交织，在你决定享受喜悦的时候，就该做好面对以后未知苦难的准备，像茨威格说的，“她那时候还太年轻，不知道所有命运馈赠的礼物，早已在暗中标好了价格”，出来混，迟早是要还的。还是希望L会更开心一点吧。总之，随着这场无声的号角吹响然后顷刻覆灭的戏剧过后，没多久就迎来了高一的暑假，假期混混模联，做做义卖，以及最本职最头疼的暑假作业，倒是给高一画上了个还算不错的句号。]]></content>
      <categories>
        <category>恋爱物语</category>
      </categories>
      <tags>
        <tag>大二</tag>
        <tag>恋爱物语</tag>
        <tag>随记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[恋与序]]></title>
    <url>%2F2019%2F02%2F12%2F%E6%81%8B-%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[序章&emsp;&emsp;14年，那时的我在中考之后脱离了低阶中二，怀着高阶的中二和以各种动漫和轻小说为蓝本构建的美好高中幻想（比如天降个超级好看的小姐姐什么的……当然这种事情我现在大二了也依旧在幻想就是了），踏入了所在城市最好的高中之一。那“高阶的中二”是个什么玩意儿呢，考完中考的那个假期由于无聊，就随意找了部看上去还不错的动漫，见了里面粉毛的女主，顿时惊为天人，励志要做一个像男主那样“亚撒西”的人，然后去找一个像女主的小姐姐（好了不用滋醒我，我知道不可能了）。由此，就开始了我漫长却又极具“趣味性”和戏剧性的感情经历。&emsp;&emsp;其实还别说，去学着日漫男主的样子混，只要你能学得像，总会有和你一样以为自己是这个世界剧本女主的人出现在你眼前（突然堂吉诃德orz），但鉴于各种原因，比如外貌什么的，你并不会那么理所当然的认为她是女主或者说你的the one，但由于很符合你目前心中的各种设定，她能很轻易地在你心里混个女三女四的地位，但能不能在你心里再往上跑点，跑个像女一女二这种地位肯定需要一定的条件，比如，颜值什么的。同时，可能是混得太像那么回事儿了吧，我收到了至今为止都是我觉得对我赞誉最高的一句话“那时候的你仿佛是闪着光的”，以至于哪怕后来我真的很想努力去做个能为某个人照点亮光的人的时候，没能做到所带来的挫败感是无比巨大的，巨大到后来的我再想从自己身上找到点光就像是从被拧干的毛巾里寻找能沁住自己的水流一般，百般无奈后只能靠铺开摊在脸上找点湿润聊以自慰与自嘲。]]></content>
      <categories>
        <category>恋爱物语</category>
      </categories>
      <tags>
        <tag>大二</tag>
        <tag>恋爱物语</tag>
        <tag>随记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hidden Markov Model]]></title>
    <url>%2F2018%2F12%2F14%2F%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Hidden Markov Model(HMM)是一种关于时序的概率模型，最初由 L. E. Baum 和其它一些学者发表在一系列的统计学论文中，随后在语言识别，自然语言处理以及生物信息等领域体现了很大的价值。本文通过个人的理解以及《统计学习方法》 中的公式推导对HMM的定义及其三个基本问题进行了简单的介绍。 Markov model 在介绍隐马尔可夫模型前我们先来介绍一下基础的马尔可夫链。马尔可夫链是一个随机模型描述序列可能的事件，其中每个事件的概率仅取决于在先前事件获得的状态 。粗略地说，以系统的当前状态为条件，其未来和过去的状态是相互独立的。 马尔可夫链的节点是状态，边是转移概率，是template CPD（条件概率分布）的一种有向状态转移表达。马尔可夫过程可以看做是一个自动机 ，以一定的概率在各个状态之间跳转。接下来以一阶马尔可夫链（first-order Markov chain）举例，N 次观测的序列的联合概率分布为： $$p(x_1,…,x_n)=p(x_1)\prod_{i=2}^n p(x_n|x_{n-1}) \quad$$ 由于每个事件发生的概率仅于前一件事件有关，即有： $$p(x_n |x_1,…,x_{n-1} )=p(x_n |x_{n-1})$$ 下面介绍马尔可夫链的一个重要性质，当n趋向于无穷时，p（Xn）趋向于一个定值。首先将每个事件的转移概率相整合成一个转移概率矩阵，假设每个事件的发生概率只与前一个事件的状态有关，共计n个状态的话，我们可以用一个n*n的矩阵P来表示转移概率，即 当我们有初始状态矩阵 时（ 表示初始状态为第i个状态的概率）则第n个状态的概率矩阵为 通过线性代数知识将转移概率矩阵做对角化，可得无穷个P矩阵相乘为一个常数，即马尔可夫链的极限收敛定理，马尔可夫链的这一性质对于其实际运用有重要的意义与作用。 HMM定义 在正常的马尔可夫模型中，状态对于观察者来说是直接可见的。这样状态的转换概率便是全部的参数。而在实际情况中，较为本质的状态转换通常是较为隐性即无法实际观测的，但是受该状态影响的变量是我们所可以观测的，由此，我们来介绍隐马尔可夫模型。在隐马尔可夫模型中，状态并不是直接可见的，但受状态影响的某些变量则是可见的。每一个隐性状态对于可观测的显性状态都有一概率分布，我们将这个概率称之为发射概率。 由此，如果我们有n个隐性状态的状态集合Q和有m个显性状态的观测集合V的话，假设I是长度为T的状态序列，O是对应的观测序列。我们就可设置转移一个$n \times n$的转移概率矩阵A和一个$m \times n$的发射概率矩阵B，π是初始状态概率向量： $n \times n$的转移概率矩阵A: $ \qquad a_{ij}=P(i_{t+1}=q_j│i_t=q_i ) \qquad i=1,…,N;j=1,…,N$$m \times n$的发射概率矩阵B: $ \qquad b_j (k)=P(o_t=v_k│i_t=q_j ) \qquad k=1,…,M;j=1,…,N$π是初始状态概率向量: $ \qquad π_i=P(i_1=q_i) \qquad i=1,…,N;j=1,…,N$ 状态转移概率矩阵A与初始状态概率向量π确定了隐藏的马尔可夫链，生成不可观测的状态序列。发射概率矩阵B确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。隐马尔可夫模型就是由基本的A,B,π三个矩阵或向量加上具体的状态集合Q和观测序列V所构成的。 接下来我以维基百科上的一个经典例子来作为算法实际运用的实例 ： “Consider two friends, Alice and Bob, who live far apart from each other and who talk together daily over the telephone about what they did that day. Bob is only interested in three activities: walking in the park, shopping, and cleaning his apartment. The choice of what to do is determined exclusively by the weather on a given day. Alice has no definite information about the weather, but she knows general trends. Based on what Bob tells her he did each day, Alice tries to guess what the weather must have been like.Alice believes that the weather operates as a discrete Markov chain. There are two states, “Rainy” and “Sunny”, but she cannot observe them directly, that is, they are hidden from her. On each day, there is a certain chance that Bob will perform one of the following activities, depending on the weather: “walk”, “shop”, or “clean”. Since Bob tells Alice about his activities, those are the observations. The entire system is that of a hidden Markov model (HMM).Alice knows the general weather trends in the area, and what Bob likes to do on average. In other words, the parameters of the HMM are known. 。” 这段稍显繁琐的文字可以转换成一张较为简洁易懂的状态转换图，如下： HMM基本问题 概率计算问题：给定模型λ(A,B,π)和观测序列O,计算在模型λ下观测序列O出现的概率P(O|λ)为多少。 学习问题：己知观测序列O,估计模型参数λ(A,B,π)使得在该模型下观测序列概率P(O|λ)最大。即用极大似然估计的方法估计参数。 预测问题：也称为解码（decoding)问题。已知模型λ(A,B,π)和观测序列O，求对给定观测序列条件概率P(I|O)最大的状态序列I。即给定观测序列，求最有可能的对应的状态序列。 概率计算 直接计算给定模型，求给定长度为T的观测序列的概率，直接计算法思路是枚举所有的长度T的状态序列，计算该状态序列与观测序列的联合概率（隐状态发射到观测），再用全概率公式对所有枚举项求和。在状态种类为N的情况下，一共有N^T种排列组合，每种组合计算联合概率的计算量为T，总的复杂度为O(T*N^T)，并不可取。 前向计算前向算法的介绍前向计算中最为重要的一步的就是前向概率的设定，对于给定隐马尔可夫模型λ(A,B,π)，定义到时刻t为止的观测序列为O且状态为 的概率为前向概率，记作 $$α_t (i)=P(o_1,o_2,…,o_t,i_t=q_i |λ)$$ 对于每一个时间点上的状态，都是用一个长度为n的概率矩阵来标记，转移到下一个状态前需要满足当前状态的观测值和已知观测序列一致，达成这个条件后即可正常转移到下一个状态，依次下去我们便可以递推地求得下一个前向概率及观测序列概率P(O|λ) 初值$$α_1 (i)=π_i b_i (o_1 ) \qquad i=1,…,N$$前向概率的定义中一共限定了两个条件，一是到当前为止的观测序列，另一个是当前的状态。所以初值的计算也有两项（观测和状态），一项是初始状态概率，另一项是发射到当前观测的概率。 递推对t=1,2…T-1$$\alpha_{t+1} (i)=[\sum_{j=1}^N \alpha_t (j) a_{ji}] b_i(o_{t+1}) \qquad i=1,…,N$$每次递推同样由两部分构成，括号中是当前状态为i且观测序列的前t个符合要求的概率，括号外的是状态i发射观测t+1的概率。 终止$$P(O|λ)=\sum_{i=1}^N[α_T (i)] \qquad i=1,…,N $$ 由于到了时间T，一共有N种状态发射了最后那个观测，所以最终的结果要用全概率公式将这些概率加起来。由于每次递推都是在前一次的基础上进行的，所以降低了复杂度。 前向算法实例以之前天气的例子来说明前向算法，HMM模型可以写成：$$A=\begin{bmatrix} 0.7 &amp; 0.3 \\ 0.4 &amp; 0.6 \\ \end{bmatrix} $$$$B=\begin{bmatrix} 0.1 &amp; 0.4 &amp; 0.5 \\ 0.6 &amp; 0.3 &amp; 0.1 \\ \end{bmatrix} $$$$π=[0.6,0.4]^T$$$$O=（散步，购物，扫除）$$假如我们想计算在（0.6,0.4）的初始状态下鲍比在未来三天分别按顺序做散步，购物，扫除的概率是多大，按照前向概率法计算，步骤如下： 计算初值——初始状态下散步的前向概率：$\alpha_1 (1)=π_1 b_1 (o_1 )=0.06$$\alpha_1 (2)=π_2 b_2 (o_1 )=0.24$ 递推计算——本质还是转移概率乘上发射概率：$\alpha_2 (1)=\sum_{j=1}^2[\alpha_1 (j) a_{j1} ] b_1 (o_2 )=(0.042+0.096)×0.4=0.0552$$\alpha_2 (2)=\sum_{j=1}^2[\alpha_1 (j) a_{j2} ] b_2 (o_2 )=(0.018+0.144)×0.3=0.0198$$\alpha_3 (1)=\sum_{j=1}^2[\alpha_3 (j) a_{j1} ] b_1 (o_3 )=(0.03864+0.00792)×0.5=0.02328$$\alpha_3 (2)=\sum_{j=1}^2[\alpha_3 (j) a_{j2} ] b_2 (o_3 )=(0.01656+0.01188)×0.5=0.01422$ 终止：$P(O│λ)=\sum_{i=1}^N[\alpha_T (i)]=0.03750 $ 后向计算后向计算与前向计算相类似，只是定义了后向概率，再次不多做赘述。 Baum-Welch算法假设给定训练数据只包含S个长度为T的观测序列O而没有对应的状态序列，目标是学习隐马尔可夫模型λ(A,B,π)的参数。我们将观测序列数据看作观测数据O，状态序列数据看作不可观测的隐数据I，那么隐马尔可夫模型事实上是一个含有隐变量的概率模型：$$P(O│λ)=\sum [P(O│I,λ)P(I|λ)]$$它的参数学习可以由EM算法实现。这里简单介绍一下EM算法，EM算法即Expectation Maximization期望最大算法。这个算法的引入可以从极大似然估计入手，极大似然估计是对于单分布问题通过已经发生的事件来估计概率模型中的位置参数，但事实上存在很多多分布问题，你只有最后的观测序列结果，但对于其具体的隐藏状态一无所知，比如经典的高斯混合模型。这个时候我们所采取的措施是先假设一组隐藏状态概率，然后进行极大似然估计，再用极大似然估计后的参数将原参数更新，这样不断迭代直至最后估计值收敛，具体的公式推导与证明只给明出处 ，在此并不细说。 确定完全数据的对数似然函数所有观测数据写成$O=(o_1,o_2,…,o_T)$,所有隐数据写成$I=(i_1,i_2,…,i_T)$，完全数据是$(O,I)=(o_1,o_2,…,o_T,i_1,i_2,…,i_T)$,。完全数据的对数似然函数是logP(O,I|λ)。 EM算法的E步：求Q函数$$Q(\lambda,\hat\lambda)=\sum_I[logP(O,I|\lambda)P(O,I|\hat\lambda)]$$其中，λ ̅是隐马尔可夫模型参数的当前估计值，λ是要极大化的隐马尔可夫模型参数。$$P(O,I│\lambda)=\pi_{i_1} b_{i_1} (o_1 ) a_{i_1 i_2 } b_{i_2} (o_2 )…a_{i_{T-1} i_T } b_{i_T} (o_T ) $$这个式子从左到右依次是初始概率、发射概率、转移概率、发射概率……于是函数Q可以写成：$$Q(\lambda,\hat\lambda)=\sum_I[log\pi_(i_1 ) P(O,I|\lambda)]\\+\sum_I(\sum_{t=1}^{T-1}[loga_{i_{t+1} \, i_t } ]) P(O,I│\hat\lambda)+\sum_I(\sum_{t=1}^Tlogb_{i_t}(o_t))P(O,I│\hat\lambda)$$式中求和都是对所有训练数据的序列总长度T进行的。这个式子是将$$P(O,I│λ)=π_{i_1} b_{i_1} (o_1 ) a_{i_1 i_2} b_{i_2} (o_2 )…a_{i_(T-1) \, i_T } b_{i_T} (o_T )$$代入$Q(\lambda ,\hat\lambda)=\sum_I logP(O,I\mid\lambda)P(O,I\mid\hat\lambda)$后，将初始概率、转移概率、发射概率这三部分乘积的对数拆分为对数之和，所以有三项。 EM算法的M步:极大化Q函数求模型参数λ(A,B,π)，由于要极大化的参数在Q函数表达式中单独地出现在3个项中，所以只需对各项分别极大化。第1项可以写成：$$\sum_Ilog\pi_{i_1} P(O,I|\hat\lambda)=\sum_{i=1}^Nlog\pi_i P(O,i_1=i|\hat\lambda)$$ 注意到$\pi_i$满足约束条件利用拉格朗日乘子法，写出拉格朗日函数。这个方法更简单明了的说法就是求条件极值，与微积分下册第五章第九节 所说内容几乎一致： $$\sum_{i=1}^Nlog\pi_i P (O,i_1=i\mid\hat\lambda)+\gamma(\sum_{i=1}^N\pi_i-1)$$ 对其求偏导数并令结果为0 $$\frac{\partial}{\partial\pi_i} [\sum_{i=1}^Nlog\pi_i P (O,i_1=i\mid\hat\lambda)+\gamma(\sum_{i=1}^N\pi_i-1)]=0 $$ 得到: $$P(O,i_1=i│\hat\lambda)+\gamma\pi_i=0 $$ 这个求导是很简单的，求和项中非i的项对π_i求导都是0，logπ的导数是1/π，γ那边求导就剩下π_i自己对自己求导，也就是γ。等式两边同时乘以π_i就得到了上式。 对i求和得到γ： $$\gamma=-P(O|\hat\lambda) $$ 代入$P(O,i_1=i│\hat\lambda)+\gamma\pi_i=0$中得到： $$\pi_i=\frac{P(o,i_1=i│\hat\lambda)}{P(O|\hat\lambda)} $$ 同理可以求得： $$a_{ij}=\frac{\sum_{i=1}^{T-1}P (O,i_t=i,i_{t+1}=j\mid\hat\lambda)}{\sum_{i=1}^{T-1}P (O,i_t=i\mid\hat\lambda)}$$$$b_j (k)=\frac{\sum_{i=1}^TP (O,i_t=j\mid\hat\lambda )I(o_t=v_(k))}{\sum_{i=1}^{T-1}P (O,i_t=i\mid\hat\lambda ) } $$ 预测算法维特比算法 维特比算法实际是用动态规划解隐马尔可夫模型预测问题，即用动态规划求概率最大路径（最优路径）。这时一条路径对应着一个状态序列。 根据动态规划原理，最优路径具有这样的特性：如果最优路径在时刻t通过结点 ,那么这一路径从结点 到终点 的部分路径，对于从 到 的所有可能的部分路径来说，必须是最优的。因为假如不是这样，那么从 到 就有另一条更好的部分路径存在，如果把它和从 到达 的部分路径连接起来，就会形成一条比原来的路径更优的路径，这是矛盾的。依据这一原理，我们只需从时刻t=l开始，递推地计算在时刻t状态为i的各条部分路径的最大概率，直至得到时刻t=T状态为i的各条路径的最大概率。时刻t=T的最大概率即为最优路径的概率P,最优路径的终结点 也同时得到。之后，为了找出最优路径的各个结点，从终结点 开始，由后向前逐步求得结点 ,得到最优路径——这就是维特比算法 。 换一种更加形象易懂的说法，假设将我们所有的状态拉成一个n*T的图，或者说一个每层有n个神经元，总共有T层的全连接神经网络。现在每一层的每个节点都会有来自上一层n个节点的连接，但我们只取其中概率最大的那一条边，将其他边全部“失活”，这样每个连接层都只剩n条边存在，不断递推直到最后一层为止，取最后一层概率最大的边为整个最优路径的概率，并不断回推得到最优路径。 维特比算法的实例 我们再以之前天气的例子来说明前向算法，将HMM模型写成： $$A=\begin{bmatrix} 0.7 &amp; 0.3 \\ 0.4 &amp; 0.6 \\ \end{bmatrix} $$ $$B=\begin{bmatrix} 0.1 &amp; 0.4 &amp; 0.5 \\ 0.6 &amp; 0.3 &amp; 0.1 \\ \end{bmatrix} $$ $$π=[0.6,0.4]^T$$ $$O=（散步，购物，扫除）$$ 假如在（0.6,0.4）的初始状态下，我们知道了Bob在接下来三天里分别按顺序做散步，购物，扫除，现在我们想知道那边的天气大概是什么样，按照维特比算法计算，步骤如下： 初始化：在t=1时，对每个状态i，求i观测o_1为散步的概率δ_1 (i)：$δ_1 (1)=0.6×0.1=0.06$$δ_1 (2)=0.4×0.6=0.24$ 在t=2时，对每个状态i，i=1,2，求在t=1时状态为j观测为散步并在t=2时状态为i观测为购物的路径的最大概率，记录此最大概率为δ_2 (i)，则：$δ_2 (i)=max⁡[\delta_1 (j) a_{ji}]b_i (o_2) \qquad (1≤j≤2)$ 通过该公式不断递推计算，我们可以很清楚的得到如下这张路径图：所以最优路径为（晴天，雨天，雨天）发生概率为（即最大概率）为0.01344]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>大二</tag>
        <tag>机器学习</tag>
        <tag>概率模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程入门]]></title>
    <url>%2F2018%2F12%2F12%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[关于Java多线程的简单入门知识注意协调不同线程驱动的任务之间对资源的使用 并发的概念 进程：每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1–n个线程。（进程是资源分配的最小单位） 线程：同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。（线程是cpu调度的最小单位） 更快的执行： 并发可以将任务分解到多个CPU上执行，但并发通常是提高运行在单处理器上的程序的性能。为什么实际运用会这么反直觉？——因为阻塞，当某个任务因为程序控制范围之外的条件（比如I/O）不能继续执行时，如果没有并发，那么整个主进程都将因此停止下来，直到外部条件发生变化。 Java的并发： Java的并发系统与操作系统不同，会共享类如内存和I/O这样的资源，因此Java多线程最基本的困难就在于协调不同线程驱动的任务之间对资源的使用，以使得这些资源不会同时被多个任务访问。 Java的线程机制是在由执行程序表示的单一进程中创建任务。 对于资源各个线程是抢占式的，调度机制会周期性地中断线程，将上下文切换到另一个线程。 多线程实现 继承Thread类 1234567891011121314151617181920212223242526class Thread1 extends Thread&#123; private String name; public Thread1(String name) &#123; this.name = name; &#125; public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(name + "运行: " + i); try &#123; sleep((int) Math.random() * 10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Thread1 mTh1=new Thread1("A"); Thread1 mTh2=new Thread1("B"); mTh1.start(); mTh2.start(); &#125;&#125; 程序启动运行main时候，java虚拟机启动一个进程，主线程main在main()调用时候被创建。随着调用两个对象的start方法，启动另外两个线程，这样整个应用就在多线程下成功运行了。注意：start()方法的调用后并不是立即执行多线程代码，而是使得该线程变为可运行态（Runnable），什么时候运行是由系统决定的。 实现java.lang.Runnable接口 12345678910111213141516171819202122232425class Thread2 implements Runnable&#123; private String name; public Thread2(String name) &#123; this.name=name; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(name + "运行 : " + i); try &#123; Thread.sleep((int) Math.random() * 10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; new Thread(new Thread2("C")).start(); new Thread(new Thread2("D")).start(); &#125;&#125; Thread2类通过实现Runnable接口，使得该类有了多线程类的特征。run（）方法是多线程程序的一个约定。所有的多线程代码都在run方法里面。在启动的多线程的时候，需要先通过Thread类的构造方法Thread(Runnable target) 构造出对象，然后调用Thread对象的start()方法来运行多线程代码。 实际上所有的多线程代码都是通过运行Thread的start()方法来运行的。因此，不管是扩展Thread类还是实现Runnable接口来实现多线程，最终还是通过Thread的对象的API来控制线程的。实现Runnable接口比继承Thread类所具有的优势： 适合多个相同的程序代码的线程去处理同一个资源 可以避免java中的单继承的限制 增加程序的健壮性，代码可以被多个线程共享，代码和数据独立 线程池只能放入实现Runable或callable类线程，不能直接放入继承Thread的类 线程状态切换 新建状态（New）：新创建了一个线程对象。 就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。 运行状态（Running）：就绪状态的线程获取了CPU，执行程序代码。 阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种： 等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁) 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（注意,sleep是不会释放持有的锁） 死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。 线程调度 调整线程优先级：优先级高的线程会获得较多的运行机会。Java线程的优先级用整数表示，取值范围是1~10Thread类有以下三个静态常量： static int MAX_PRIORITY;//线程可以具有的最高优先级，取值为10。static int MIN_PRIORITY;//线程可以具有的最低优先级，取值为1。static int NORM_PRIORITY;//分配给线程的默认优先级，取值为5。 Thread类的setPriority()和getPriority()方法分别用来设置和获取线程优先级。每个线程都有默认优先级，主线程的默认优先级为Thread.NORM_PRIORITY线程的优先级有继承关系，比如A线程中创建了B线程，那么B将和A具有相同的优先级。JVM提供了10个线程优先级，但与常见的操作系统不能很好的映射。如果希望程序能移植到各个操作系统中，应该仅仅使用Thread类有以下三个静态常量作为优先级，这样能保证同样的优先级采用了同样的调度方式。 线程睡眠：Thread.sleep(long millis)方法，使线程转到阻塞状态。millis：设定睡眠的时间(ms)当睡眠结束后，转为就绪（Runnable）状态。 线程等待：Object类中的wait()方法，导致当前的线程等待，直到其他线程调用此对象的notify()方法或notifyAll()唤醒方法。这个两个唤醒方法也是Object类中的方法，行为等价于调用wait(0)一样。 线程让步：Thread.yield()方法，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。 线程加入：join()方法，等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。 线程唤醒：Object类中的notify()方法，唤醒在此对象监视器等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程（选择是任意性的，并在对实现做出决定时发生）线程通过调用其中一个 wait 方法，在对象的监视器上等待。 直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程。被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。 常用函数 Thread.sleep(long millis)：在指定的毫秒数内让当前正在执行的线程休眠（暂停执行） Thread.join()：指等待该线程终止。该线程是指的主线程等待子线程的终止。也就是在子线程调用了join()方法后面的代码，只有等到子线程结束了才能执行。在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。 Thread.yield()：暂停当前正在执行的线程对象，并执行其他线程。yield()应该做的是让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。 Thread.setPriority(): 更改线程的优先级。 Obj.wait()：暂停当前线程，释放CPU控制权，释放对象锁的控制。与Obj.notify()必须要与synchronized(Obj)一起使用，也就是wait,与notify是针对已经获取了Obj锁进行操作： 从语法角度来说就是Obj.wait(),Obj.notify必须在synchronized(Obj){…}语句块内。 从功能上来说wait就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的notify()唤醒该线程，才能继续获取对象锁，并继续执行。但有一点需要注意的是notify()调用后，并不是马上就释放对象锁的，而是在相应的synchronized(){}语句块执行结束，自动释放锁后，JVM会在wait()对象锁的线程中随机选取一线程，赋予其对象锁，唤醒线程，继续执行。 线程类方法： sleep(): 强迫一个线程睡眠Ｎ毫秒。isAlive(): 判断一个线程是否存活。join(): 等待线程终止。activeCount(): 程序中活跃的线程数。enumerate(): 枚举程序中的线程。currentThread(): 得到当前线程。isDaemon(): 一个线程是否为守护线程。setDaemon(): 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束)setPriority(): 设置一个线程的优先级。 线程同步 synchronized关键字的作用域： 是某个对象实例内，synchronized aMethod(){}可以防止多个线程同时访问这个对象的synchronized方法（如果一个对象有多个synchronized方法，只要一个线程访问了其中的一个synchronized方法，其它线程不能同时访问这个对象中任何一个synchronized方法）。这时，不同的对象实例的synchronized方法是不相干扰的。也就是说，其它线程照样可以同时访问相同类的另一个对象实例中的synchronized方法； 是某个类的范围，synchronized static aStaticMethod{}防止多个线程同时访问这个类中的synchronized static 方法。它可以对类的所有对象实例起作用。 synchronized关键字是不能继承的，继承类需要你显式的指定它的某个方法为synchronized方法； 线程同步的TIPS 线程同步的目的是为了保护多个线程反问一个资源时对资源的破坏。 线程同步方法是通过锁来实现，每个对象都有且仅有一个锁，这个锁与一个特定的对象关联，线程一旦获取了对象锁，其他访问该对象的线程就无法再访问该对象的其他非同步方法。 对于静态同步方法，锁是针对这个类的，锁对象是该类的Class对象。静态和非静态方法的锁互不干预。一个线程获得锁，当在一个同步方法中访问另外对象上的同步方法时，会获取这两个对象锁。 对于同步，要时刻清醒在哪个对象上同步，这是关键。 编写线程安全的类，需要时刻注意对多个线程竞争访问资源的逻辑和安全做出正确的判断，对“原子”操作做出分析，并保证原子操作期间别的线程无法访问竞争资源。 当多个线程等待一个对象锁时，没有获取到锁的线程将发生阻塞。 代码示例创造一个Object Lock来充当锁，用Lock类的变量lockon作为是否循环wait()语句的条件：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class Lock&#123; int lockon; Lock()&#123; this.lockon = 1; &#125;&#125;class ThTest implements Runnable&#123; Lock lock; ThTest(Lock lock)&#123; this.lock = lock; &#125; public void run() &#123; synchronized(lock) &#123; while(lock.lockon==1) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(lock.lockon+"Lock is down. Next it will be on."); try &#123; Thread.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.lockon = 1; lock.notify(); &#125; &#125;&#125;class ThRest implements Runnable&#123; Lock lock; ThRest(Lock lock)&#123; this.lock = lock; &#125; public void run() &#123; synchronized(lock) &#123; while(lock.lockon==0) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(lock.lockon+"Lock is on. Next it will be down."); try &#123; Thread.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.lockon = 0; lock.notify(); &#125; &#125;&#125;public class Test8_3 &#123; public static void main(String args[]) &#123; Lock lock = new Lock(); ThTest thtest = new ThTest(lock); ThRest threst = new ThRest(lock); new Thread(thtest).start(); new Thread(threst).start(); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>大二</tag>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradient Descent]]></title>
    <url>%2F2018%2F12%2F11%2F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%2F</url>
    <content type="text"><![CDATA[梯度下降算法是机器学习领域中非常常用的优化算法。本文通过对梯度下降算法、AdaGrad算法、SGD算法、动量算法以及牛顿动量算法的介绍，将比较基础的梯度下降算法变种介绍给读者。 目的对于一个含参的函数，通过不断求解当前点的梯度值，并以该梯度值成负比例的步长不断更新所求点，以求解出使其函数值最小的一组参数。 思想对于一个含参的函数，以与函数在当前点梯度（近似）成负比例的步长来不断更新该参数，使其不断向该参数偏导为0的点逼近，以找到函数的局部最小值。 当我们从损失函数的某一点出发，在该点附近做出以常数η为参数的一个邻域，根据微积分所学的知识可知，我们在该邻域上一定可以找出一个找到极小值。我们以该极小值点为下一步我们需要跟进的点，更新之后我们再在该点附近做出以常数η为参数的一个邻域并重复以上过程。通过这样的不断更新，我们理论上一定可以找出一个全局的极小值点或者是导数为0的驻点。关于在某一邻域上如何找到该邻域上的局部最小值点。我们可以通过泰勒展开，该邻域上的损失函数可以近似写成 $L(\theta)=L(a,b)+u(\theta_1-a)+v(\theta_2-b)$也就是我们所熟知的全微分方程。令 $\Delta\theta_1=\theta_1-a;\Delta\theta_2=\theta_2-b$ 因为L(a,b)为一个常数，所以L的极小值直接取决于 u+ v同时我们可以将其书写成向量的形式$(\Delta\theta_1,\Delta\theta_2)·(u,v)$显然$(\Delta\theta_1,\Delta\theta_2)$与(u,v)反向时L最小，即$$ \begin{bmatrix} \Delta\theta_1 \\ \Delta\theta_2 \end{bmatrix}=-\eta \begin{bmatrix} u \\ v \end{bmatrix}$$其中u和v分别为函数的偏导数值且η取值越小该结果越准确。 实现用均方误差构造一个以函数f为自变量的二元损失函数 ：(因为f = w*x + b所以也可以看出以w和b为自变量的函数)1L(f)=L(w,b)=((y - (w * x + b))**2).sum()/len(x) 首先考虑只有一个参数 w 的损失函数，随机的选取一个初始点，计算此时 L 对 w 的微分，然后顺着切线下降的方向更改 w 的值1w = w - grad(w)*learning_rate 此后，w会不断靠近微分近似为0的点以达成目标。同样方法求出所有参数的值。而实际上我们所需要的是不断同时更新损失函数所需要的所有参数的值，我们在编程中只需要让所有参数的更新在同一次迭代过程中更新即可，因为当迭代次数足够多的时候，每一次的迭代都可以看成在很短的一个小时间段中进行，因此每次迭代的不同参数更新可以近似看成时在同一时间段所更新的，即达到了我们要求梯度下降同时更新损失函数中含有的所有参数的要求。 问题学习率的不确定性所带来的一系列问题，比如若学习率过大，导致每次更新的步长过大，而过大的步长有可能并不符合实际更新的情况，导致了过大的学习率会使不断更新的参数在最值点上方震荡，甚至直接跨过最值点使损失函数值不断增大，无法逼近最值点；如果学习率过小，尽管较小的学习率符合我们梯度下降的数学原理，可以求得较为准确的符合我们预期的参数值。但是同时，过小的学习率会使更新的速度较慢，在计算中往往导致浪费计算机时间与性能，在我们的日常实际生活运用中可能会等不及出结果。 优化思路通常刚开始，初始点会距离极值点比较远，所以使用大一点的学习率。而更新好几次参数之后呢，此时的参数点比较靠近最低点，故而可适当减小学习率。即随着次数的增加，使学习率的大小与更新次数呈负相关，例如采取将学习率除以次数加一的开根号$lr/\sqrt{t+1} \quad$等方法。 优化算法AdaGrad算法（适应性梯度算法）：每个参数的学习率都除上之前该参数所有微分的均方根[。为每一个参数保留一个学习率以提升在稀疏梯度上的性能。12lr_b += b_grad ** 2b -= lr/np.sqrt(lr_b) * b_grad 适应性梯度算法中的学习率($\eta_t/\sigma_t$)由两部分组成，其中 $\eta_t=\eta/\sqrt{t+1} \quad$即随着迭代次数的增加，不断削减学习率使每次更新的步长不断变小。$\sigma_t=\sqrt{\frac{\sum_{i=1}^t(g^i)^2\quad}{(t+1)}} \quad$即之前该参数所有微分和的均方根，用此作为分母用意在：如果走到当前点的微分过小，可以控制学习率让其步长适当增大一点；如果走到当前点的微分过大，通过控制学习率使其步长适当减小一点。如此，得到我们的学习率$\frac{\eta_t}{\sigma_t}=\frac{\eta}{\sqrt{\sum_{i=1}^t(g^i)^2\quad} \quad}g^t$接下来给出更本质的解释：适应性梯度算法中学习率近似于(|一阶导数|/二阶导数)。对于只有一个自变量的函数，我们可以用其一阶导数来表示该点的下降速率。但是对于有多个自变量的函数，每更新一次，所选取合适点的标准如果只有一阶导数唯一一个衡量标准显然是不合适的。而二次微分可以在一定程度上反映出当前点到偏导为0的驻点的距离。综合考虑着这两个因子，可以较好地提供出一个符合我们期望的学习率。而对于二次微分，我们用一次微分的均方根来表示，它可以在一定程度上反映二次微分的大小。例如如果二次微分较小，则一次微分图像斜率较缓，那么一次微分的均方根相对而言会较小。适应性梯度算法最好的举例便是一元二次函数 ，其最佳步长为 即|2ax+b|/2a上下分别是该一元二次函数的一次微分和二次微分。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122import matplotlib.pyplot as pltimport numpy as npfrom mpl_toolkits.mplot3d import Axes3Dimport randomw_init = 4.2b_init = -150def f(x): return w_init * x + b_initdef initDate(): x_data = [] y_data = [] for i in range(10): x = random.randint(-99,99) x_data.append(x) y_data.append(f(x)+f(x)/10*random.randint(-1,1)) # 给数据加点噪声，使过程更加真实一点 return x_data,y_datadef exhaustion(x_data,y_data): # 通过穷举法试探出使均方误差最小的一组b&amp;w x = np.arange(-abs(1.5*b_init),abs(1.5*b_init),abs(b_init)/20) #bias Y= np.arange(-abs(1.5*w_init),abs(1.5*w_init),abs(w_init)/20) #weight Z = np.zeros((len(x),len(y))) X,Y = np.meshgrid(x,y) #return两个矩阵,X的行向量是向量x的简单复制,Y的列向量是向量y的简单复制 x_data = np.array(x_data) y_data = np.array(y_data) for i in range(len(x)): for j in range(len(y)): b = x[i] w = y[j] Z[j][i] = ((y_data - b - w * x_data)**2).sum()/len(x_data) # Z值最小的那一组x[i]y[j]就是我们所期望的使f值最小的b，w return X,Y,Zdef gradientDescent(x_data,y_data): #initial: b = 0 w = 0 lr = 1 # learning rate iteration = 100000 b_history = [b] w_history = [w]# 我们实际用gandient descent求出的b&amp;w lr_b = 0 lr_w = 0 for i in range(iteration): #不断向偏导为0的驻点靠拢，以获取均方误差最小的一组解w、b x = np.array(x_data) y = np.array(y_data) b_grad = -2.0*(y - b - w*x) w_grad = -2.0*(y - b - w*x)*x b_grad = b_grad.sum()/len(x) w_grad = w_grad.sum()/len(x) lr_b += b_grad ** 2 lr_w += w_grad ** 2 #update parameters: b -= lr/np.sqrt(lr_b) * b_grad w -= lr/np.sqrt(lr_w) * w_grad #store parameters for plotting: b_history.append(b) w_history.append(w) return b_history,w_historydef getPicture(b_history,w_history,X,Y,Z): plt.figure('gradient_descent') plt.contourf(X,Y,Z,50,alpha=0.5,cmap=plt.get_cmap('jet')) plt.plot([b_init],[w_init],'x',ms=12,markeredgewidth=3,color='orange') plt.plot(b_history,w_history,'o-',ms=3,lw=1.5,color='black') plt.xlim(-abs(1.5*b_init),abs(1.5*b_init)) plt.ylim(-abs(1.5*w_init),abs(1.5*w_init)) plt.xlabel(r'$b$',fontsize=16) plt.ylabel(r'$w$',fontsize=16)def get3D(b_history,w_history,X,Y,Z): #为了画好看的三维图并考虑到memory error强行又弄了组数据 b_h = b_history[::1000] w_h = w_history[::1000] B,W = np.meshgrid(b_h,w_h) Q = np.zeros(len(b_h)) for i in range(len(b_h)): for n in range(len(x_data)): Q[i] = Q[i] + (y_data[n] - b_h[i] - w_h[i] * x_data[n])**2 Q[i] = Q[i]/len(x_data) # 均方误差 ax = Axes3D(plt.figure('三维图')) ax.plot_surface(X,Y,Z,cmap = 'rainbow') ax.plot([b_init],[w_init],'x',ms=12,markeredgewidth=3,color = 'orange') ax.plot(b_h,w_h,Q,'o-',ms=3,lw=1.5,color='black') ax.set_xlabel('--b--') ax.set_ylabel('--w--') ax.set_zlabel('--z--') ax.set_title('3D')def initPicture(b,w): plt.figure('initial') x = np.linspace(-99,99) y_init = f(x) # 所求目标函数的函数值 y_grad = w*x+b # 梯度下降求出的函数所对应的函数值 plt.plot(x,y_init,'.') plt.plot(x,y_grad)if __name__ == '__main__': x_data,y_data = initDate() # 获取实验数据 X,Y,Z = exhaustion(x_data,y_data) # X&amp;Y为网格图，Z为其函数值 b_history,w_history = gradientDescent(x_data,y_data) b = b_history[-1];print(b) w = w_history[-1];print(w) getPicture(b_history,w_history,X,Y,Z) # 绘制图像 get3D(b_history,w_history,X,Y,Z) initPicture(b,w) plt.show() SGD算法（Stochastic Gradient Descent随机梯度下降算法）：随机梯度下降算法与基础的梯度下降极为相似，唯一的不同点在于它是从某一个样本点出发而并非像梯度下降算法那样每次都考虑整体的数值同时更新。随机梯度下降算法的优点是很明显的，计算的速度和效率要比普通的梯度下降快得多。而这样所带来的缺点就是随机梯度下降算法的路线可能会不断抖动，并且可能优化过程充满震荡，但同时，正是因为这种大幅度的震荡，有时可以解决大部分梯度下降算法都会面临的一个绝对难题，即“陷进”局部最小值点。大部分梯度下降算法在优化过程中很可能会被困在某个驻点，而随机梯度下降算法有时可以通过优化过程的抖动而逃离当前的局部最小值点。这也是很多自适应优化算法在实际训练出的结果都不如随机梯度下降算法的原因。 Momentum算法（动量算法）：momentum即动量，该算法在普通的梯度下降中引入了动量这个因子是因为普通的梯度下降算法，在每一次更新完成后在当前点的附近邻域上所求得的局部最小值点的方向很大可能是和之前一步的方向几乎相反的，这就导致了普通梯度下降算法在更新当前点时很容易不断震荡，效率低下不符合我们的期望。由此我们采用了动量算法，即增加一个变量v表示速度更新，在每次参数更新的时候加上计算出的当前的速度更新值v= γ· v - η·grad（其中参数γ为衰减权重，一般为0.9，可以让早期的梯度对当前梯度的影响越来越小）其中这个0.9倍上一个点的梯度下降方向就表示了当前该点的动量，让该动量与当前点的梯度方向做矢量和。之后将原参数更新θ = θ + v即可。这样每次更新就会多更新一部分上一次迭代的更新量，来平滑这一次迭代的梯度。从物理的角度来解释，就像是一个小球在滚落的过程中会受其自身的历史动量所影响，所以才称为动量算法。动量算法中学习率越大（实际情况中一般学习率比较小，例如0.001），当前梯度对现在更新的影响也就越大；v中含有所有速度更新值，可以反映历史时刻梯度方向。而由于动量积攒了历史的梯度，如点P前一刻的梯度与当前的梯度方向几乎相反。因此原本在P点原本要大幅徘徊的梯度，主要受到前一时刻的影响，而导致在当前时刻的梯度幅度减小。要是当前时刻的梯度与历史时刻梯度方向相似，这种趋势在当前时刻则会加强；要是不同，则当前时刻的梯度方向减弱。 NAG算法（牛顿动量算法Nesterov accelerated gradient）：由之前所说，动量算法每下降一步都是由前面下降方向的一个累积和当前点的梯度方向组合而成。那么既然每一步都要将两个梯度方向（历史梯度、当前梯度）做一个合并再下降，那为什么不先按照历史梯度往前走那么一小步，按照前面一小步位置的“超前梯度”来做梯度合并呢？所以牛顿动量算法和动量算法唯一的区别就在于它的梯度不是根据当前参数位置，而是根据先走了一步本来计划要走的一步后达到参数的位置计算出来的。具体做法为先临时更新θ’ = θ + γ· v然后计算临时点的梯度grad’并计算出速度更新v= γ· v - η·grad’最后应用更新θ = θ + v即可。牛顿动量算法其实是相比于动量算法多考虑了本次梯度相对于上次梯度的变化量，而这个变化量本质是对于目标函数二阶导的近似。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>大二</tag>
        <tag>优化算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sort]]></title>
    <url>%2F2018%2F12%2F09%2FSort%2F</url>
    <content type="text"><![CDATA[常见的nlogn排序算法介绍与实现：快速排序，希尔排序，归并排序，堆排序，排序树 快排（nlogn）：将列表以首元(a[0])为判断依据隔成两部分,第一部分全部小于首元，第二部分全部大于等于首元。（复杂度n）重复上述过程至所有元素（次数为logn） void quick_sort(int a[],int low,int high); int find_pos(int a[],int low,int high); 希尔（nlogn）：将列表以不同的步长进行划分，常用n/2不断划分至步长为1。每次划分后将各子列表排序即可。希尔复杂度最优时为1.3n，分析起来好像有点复杂orz void shell_sort(int a[],int n); void step_wise(int a[],int D,int n); 归并（nlogn）：将列表不断二分成两份列表，当分成每个子列表的长度都为1时显然每个子列表都有序（次数logn），然后将有序的两个子列表不断合并并使之有序（复杂度n） void merge_sort(int a[], int b[], int start, int end); void Merge(int a[],int b[], int start, int mid, int end); 堆排（nlogn）：大顶堆（二叉树）的性质是父节点大于子节点，先通过这个性质建个堆。（tips：建堆的时候用完全二叉树的性质a[i]d的左子树为a[2*i]，所以存值从a[1]开始，a[0]用来暂存值就好啦）此时a[1]一定是最大数，将a[1]（堆顶）与末元a[n-1]（最后一个叶节点）交换后将a[n-1]忽略，不进入下次堆排（n–）再将堆的性质恢复（logn），依次进行至堆顶（n） void heap_sort(int a[],int n); void sift(int a[],int r,int n); 排序树（nlogn）：右节点&gt;父节点&gt;左节点，建立后将该二叉树中序遍历即可。 void tree_sort(int a[],int n); void setting(TNode* tree,int x); void tree_order(TNode* tree); 基数排序 (d(n+r))：依次按不同位数（d）进行关键字的比较（需要构建队列（队列大小r）） 以下附实现的C语言代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179​#include &lt;stdio.h&gt; #include&lt;stdlib.h&gt;#include&lt;time.h&gt; typedef struct node&#123; int data; struct node* lc; struct node* rc;&#125;TNode;void quick_sort(int a[],int low,int high);int find_pos(int a[],int low,int high);void shell_sort(int a[],int n);void step_wise(int a[],int D,int n);void choose_sort(int a[],int n);void merge_sort(int a[], int b[], int start, int end);void Merge(int a[],int b[], int start, int mid, int end);void heap_sort(int a[],int n);void sift(int a[],int r,int n);void tree_sort(int a[],int n); TNode* secrach(TNode* tree,int x);void setting(TNode* tree,int x);void tree_order(TNode* tree);int main()&#123; int a[10];int b[10]; srand( (unsigned int)(time(0)) ); for(int i=0;i&lt;10;i++)&#123; a[i]=rand()%100+1; printf("%02d\t",a[i]); &#125;printf("\n"); //quick_sort(a,0,9); //shell_sort(a,10); //choose_sort(a,10); //merge_sort(a,b,0,9); //heap_sort(a,10); //tree_sort(a,10); for(int i=0;i&lt;10;i++) printf("%02d\t",a[i]); &#125;void quick_sort(int a[],int low,int high)&#123; if(low&gt;=high) return; int idx = find_pos(a,low,high); quick_sort(a,low,idx-1); quick_sort(a,idx+1,high);&#125;int find_pos(int a[],int low,int high)&#123; int temp = a[low]; while(low&lt;high)&#123; while(low&lt;high&amp;&amp;a[high]&gt;temp) high--; a[low] = a[high]; while(low&lt;high&amp;&amp;a[low]&lt;=temp) low++; a[high] = a[low]; &#125; a[low] = temp; return low;&#125;void shell_sort(int a[],int n)&#123; int d = n/2; while(d&gt;=1)&#123; step_wise(a,d,n); d = d/2; &#125;&#125;void step_wise(int a[],int D,int n)&#123; for(int d=0;d&lt;D;d++)&#123; for(int i=d+D;i&lt;n;i=i+D)&#123; int temp = a[i];int j=i; for(j=i;j-D&gt;=0;j=j-D)&#123; if(temp&lt;a[j-D]) a[j] = a[j-D]; else break; &#125; a[j] = temp; &#125; &#125;&#125;void choose_sort(int a[],int n)&#123;//选择排序 for (int i = 0;i&lt;n;i++)&#123; for (int j = i;j&lt;n;j++)&#123; if (a[j]&lt;a[i])&#123; int ex = a[i]; a[i] = a[j]; a[j] = ex; &#125; &#125; &#125;&#125;void Merge(int a[],int b[], int start, int mid, int end)&#123;//合并a、b数组并排序 int i = start, j=mid+1, k = start; while(i!=mid+1 &amp;&amp; j!=end+1)&#123; if(a[i] &gt; a[j]) b[k++] = a[j++]; else b[k++] = a[i++]; &#125; while(i != mid+1) b[k++] = a[i++]; while(j != end+1) b[k++] = a[j++]; for(i=start; i&lt;=end; i++) a[i] = b[i];&#125;void merge_sort(int a[], int b[], int start, int end)&#123; if(start &lt; end)&#123; int mid = (start + end) / 2; merge_sort(a, b, start, mid); merge_sort(a, b, mid+1, end); Merge(a, b, start, mid, end); &#125;&#125;void sift(int p[],int r,int n)&#123;//树根p[r]（可能是子树的树根）最值性质被破坏的堆 int k = 2*r; int temp = p[r]; while(k&lt;=n)&#123;//尽力将p[r]沉到最底，以确保整体性质的正确 if(k&lt;n &amp;&amp; p[k+1]&gt;p[k]) k++;//k&lt;n防止k+1越界 if(temp&gt;=p[k]) break; p[r] = p[k];r = k;//先不急交换完p[r]，我们看看p[r]最后能沉到哪 k = 2*r; &#125; p[r] = temp; &#125;void heap_sort(int a[],int n)&#123; n = n+1;int p[n]; for(int i=1;i&lt;n;i++) p[i]=a[i-1]; for(int i=n/2;i&gt;=1;i--) sift(p,i,n); for(int i=n;i&gt;=2;i--)&#123; p[0] = p[1]; p[1] = p[i]; p[i] = p[0]; sift(p,1,i-1); &#125; for(int i=1;i&lt;n;i++) a[i-1]=p[i]; &#125;void tree_sort(int a[],int n)&#123; TNode* tree = (TNode*)malloc(sizeof(TNode)); tree-&gt;lc=NULL;tree-&gt;rc=NULL;tree-&gt;data=a[0]; for(int i=1;i&lt;n;i++) setting(tree,a[i]); tree_order(tree);&#125;TNode* secrach(TNode* tree,int x)&#123; TNode* p; while(tree!=NULL)&#123; if(x&lt;tree-&gt;data)&#123; p=tree;tree=tree-&gt;lc; &#125; else&#123; p=tree;tree=tree-&gt;rc; &#125; &#125; return p;&#125;void setting(TNode* tree,int x)&#123; TNode* p = secrach(tree,x); TNode* q = (TNode*)malloc(sizeof(TNode)); q-&gt;data=x;q-&gt;lc=NULL;q-&gt;rc=NULL; if(p==NULL)&#123; p=q;return; &#125; if(x&lt;p-&gt;data) p-&gt;lc=q; else p-&gt;rc=q; return;&#125;void tree_order(TNode* tree)&#123; if(tree==NULL) return; tree_order(tree-&gt;lc); printf("%02d\t",tree-&gt;data); tree_order(tree-&gt;rc);&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图的遍历]]></title>
    <url>%2F2018%2F12%2F09%2F%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[这是一个以邻接表为基础的遍历……包括DFS的递归非递归实现以及BFS队列实现 递归DFS：12345678910111213141516171819202122​int main()&#123; TGraph* G = (TGraph*)malloc(sizeof(TGraph)); graph_init(G);//稍微初始化一下我们的图 int visited[N];for(int i=0;i&lt;N;i++) visited[i]=0; for(int i=0;i&lt;N;i++)&#123; if(visited[i]==0)&#123; DFS(G,visited,i); printf("\n"); &#125; &#125;&#125; void DFS(TGraph* G,int visited[N],int i)&#123; printf("%d ",G-&gt;adjlist[i].vex);visited[i]=1; ENode* p = G-&gt;adjlist[i].next; while(p!=NULL)&#123; if(visited[p-&gt;vex]==0)&#123; DFS(G,visited,p-&gt;vex); &#125; p = p -&gt; next; &#125;&#125; 非递归DFS：12345678910111213141516171819202122232425​void dfs(TGraph* G,int visited[N])&#123; Tqueue* stack = stack_init(G-&gt;nv); for(int i=0;i&lt;G-&gt;nv;i++)&#123; if(visited[i]==1) break; else&#123; stack-&gt;qu[stack-&gt;rear++] = i; visited[i]=1; while(stack-&gt;front!=stack-&gt;rear)&#123; ENode* temp = G-&gt;adjlist[stack-&gt;qu[stack-&gt;rear-1]].next; printf("%d ",stack-&gt;qu[--stack-&gt;rear]); while(1)&#123; if(temp==NULL) break; if(visited[temp-&gt;vex]==0)&#123; stack-&gt;qu[stack-&gt;rear++] = temp-&gt;vex; visited[temp-&gt;vex]=1;break; &#125; temp = temp-&gt;next; &#125; &#125; &#125; &#125; free(stack);&#125; BFS：123456789101112131415161718192021​void bfs(TGraph* G,int visited[N])&#123; Tqueue* queue = queue_init(G-&gt;nv); for(int i=0;i&lt;G-&gt;nv;i++)&#123; if(visited[i]==1) break; queue-&gt;qu[queue-&gt;rear++%G-&gt;nv] = i;visited[i]=1;//简单地借用一下循环队列的思想 while(queue-&gt;front%G-&gt;nv!=queue-&gt;rear%G-&gt;nv)&#123; ENode* temp = G-&gt;adjlist[queue-&gt;qu[(queue-&gt;front)%G-&gt;nv]].next; printf("%d ",queue-&gt;qu[(queue-&gt;front++)%G-&gt;nv]); while(1)&#123; if(temp==NULL) break; if(visited[temp-&gt;vex]==0)&#123; queue-&gt;qu[queue-&gt;rear++%G-&gt;nv] = temp-&gt;vex; visited[temp-&gt;vex]=1;break; &#125; temp = temp-&gt;next; &#125; &#125; &#125; free(queue);&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图的储存结构]]></title>
    <url>%2F2018%2F12%2F09%2F%E5%9B%BE%E7%9A%84%E5%82%A8%E5%AD%98%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[图的储存结构：邻接矩阵，邻接表，十字链表，邻接多重表，边集数组实现方式：矩阵，链表构成的数组*3，三元组 邻接矩阵（n个结点，构造n*n的矩阵，各点值可达为1，不可达为0）当我们需要将权重赋在矩阵上时，各点值若可达，则为其权重；不可达则为∞（INT_MAX）；对角元为0 邻接表（n个结点，构造有n个首结点的数组，每个首结点拉出一条含该首结点所有可达结点的链表） 123456789101112131415​typedef struct node&#123; int vex; int cost;//对应VNode到该点的权重 struct node* next;&#125;ENode;typedef struct&#123; int vex; ENode* next;&#125;VNode;typedef struct&#123; VNode adjlist[N]; int nv,ne;&#125;TGraph;​ 十字链表（有向图）相比于邻接表，VNode多开了个指针域让你指向以该点为弧尾的第一个弧结点，便于同时求出度和入度，将原先的TNode变成有两个结点编号和两个指针域（一个指向弧头相同的下一条弧，一个指向弧尾相同的下一条弧）的Vex（弧结点）。 12345678910111213141516​typedef struct vex&#123; int headvex,tailvex;//弧头（尾）顶点编号 int cost; struct vex* hlink,tlink;//指向弧头（尾）相同的下一条弧&#125;Vex;typedef struct&#123; int data;//存放顶点信息 Vex* firstin;//以该点为弧头的第一个弧结点 Vex* firstout;//以该点为弧尾的第一个弧结点&#125;VNode;typedef struct&#123; VNode orthlist[N]; int nv,ne;&#125;OrthGraph;​ 邻接多重表（无向图）相比于邻接表，VNode不变，将原先的TNode变成有两个结点编号和两个指针域（一个指向下一条依附）的Vex（弧结点） 12345678910111213141516​typedef struct vex&#123; int ivex,jvex;//依附于该边的两个顶点编号 int cost; struct vex* ilink;//指向下一条依附于顶点ivex的边 struct vex* jlink;//指向下一条依附于顶点jvex的边&#125;Vex;typedef struct&#123; int data;//存放顶点信息 Vex* firstedge;//指向第一条依附于该顶点的边结点&#125;VNode;typedef struct&#123; VNode orthlist[N]; int nv,ne;&#125;OrthGraph;​ （TIPS_对比：十字链表注重对边的操作，而邻接多重表更注重对点的操作） 边集数组（类似于三元组）12345678910111213141516​typedef struct&#123; int vex; int gno;//连通分量，用于kruskal算法&#125;TVex;typedef struct&#123; int va,vb; int cost; &#125;TEdge;typedef struct&#123; TVex* pv; TEdge* pe; int nv,ne;&#125;TGraph;​]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最小生成树]]></title>
    <url>%2F2018%2F12%2F08%2F%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%2F</url>
    <content type="text"><![CDATA[Prime：从点0开始不断拉相邻权重最小且不构成回路的点进来Kruskal：在原图中不断找权重最小的边“记录在案”，保证不构成回路 Prime算法（稠密矩阵；邻接矩阵）从点0开始不断拉相邻权重最小且不构成回路的点进来（形成一个超点） 1234567891011121314151617181920212223242526272829303132​void prime(int G[N][N])&#123; Edge edges[N]; for(int i=0;i&lt;N;i++)&#123; edges[i].vex = 0;//表示"0"到各个节点 edges[i].cost = G[0][i];//距离 &#125; edges[0].cost = 0;//距离"0"表示不可达 printf("%d ",edges[0].vex); for(int a=1;a&lt;N;a++)&#123; int k = select(edges); printf("%d(last: %d) ",k,edges[k].vex); edges[k].cost = 0; for(int i=0;i&lt;N;i++)&#123; if(G[k][i]&lt;edges[i].cost)&#123; edges[i].vex = k;//表示到i这个点是从k走更近一点 edges[i].cost = G[k][i]; &#125; &#125; &#125;&#125;int select(Edge edges[])&#123; int val = INT_MAX;int idx = -1; for(int i=0;i&lt;N;i++)&#123; if(edges[i].cost&lt;val&amp;&amp;edges[i].cost&gt;0)&#123; val = edges[i].cost; idx = i; &#125; &#125; return idx;&#125;​ Kruskal（稀疏矩阵；邻接表）在原图中不断找权重最小的边“记录在案”，保证不构成回路（与标记过的点不属于同一连通分量gno） 123456789101112131415161718192021​void kruskal(TGraph* G)&#123; heapsort(G);//稍微排个序 int idx=1;int num=0; for(int i=1;i&lt;G-&gt;nv;i++)&#123; while(1)&#123; if(G-&gt;pv[G-&gt;pe[idx].va].gno!=G-&gt;pv[G-&gt;pe[idx].vb].gno)&#123; int a=G-&gt;pv[G-&gt;pe[idx].va].gno,b=G-&gt;pv[G-&gt;pe[idx].vb].gno; for(int j=1;j&lt;idx;j++)&#123; if(G-&gt;pv[G-&gt;pe[j].va].gno==a) G-&gt;pv[G-&gt;pe[j].va].gno=b; if(G-&gt;pv[G-&gt;pe[j].vb].gno==a) G-&gt;pv[G-&gt;pe[j].vb].gno=b; &#125; G-&gt;pv[G-&gt;pe[idx].va].gno=b; printf("%d-%d ",G-&gt;pe[idx].va,G-&gt;pe[idx].vb);break; &#125; else idx++; &#125; idx++; &#125;&#125;​]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图的最短路径]]></title>
    <url>%2F2018%2F12%2F08%2F%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[Dijkstra : 从点v0开始，不断把距V0距离最小的点拉进超点（注意：权重值一定要是正的）Floyd : 如果i-&gt;k-&gt;j的距离比直接i-&gt;j要短的话，更新一下dist的距离和path的路径 Dijkstra从点v0开始，不断把距V0距离最小的点拉进超点（注意：权重值一定要是正的） 1234567891011121314151617181920212223242526272829​void dijkstra(int G[N][N],int v0,int path[],int s[])&#123; int dist[N]; for(int i=0;i&lt;N;i++)&#123; dist[i]=G[v0][i]; if(dist[i]&lt;INT_MAX) path[i]=v0;//记录前驱，即“0” else path[i] = -1; &#125;dist[v0]=-1; for(int a=0;a&lt;N;a++)&#123; int idx=-1,min=INT_MAX; for(int i=0;i&lt;N;i++)&#123; if(dist[i]&gt;0&amp;&amp;dist[i]&lt;min)&#123; idx = i;min = dist[i]; &#125; &#125; if(idx&lt;0) break;s[idx]=min; dist[idx] = -1; for(int i=0;i&lt;N;i++)&#123; if(dist[i]&gt;0&amp;&amp;G[idx][i]!=INT_MAX&amp;&amp;min+G[idx][i]&lt;dist[i])&#123; dist[i]=min+G[idx][i]; path[i] = idx; &#125; &#125; &#125;&#125;void print(int path[N],int s[N])&#123; for(int i=0;i&lt;N;i++) if(path[i]&gt;=0) printf("node :%2d(pre:%2d) s:%d \n",i,path[i],s[i]);&#125;​ Floyd如果i-&gt;k-&gt;j的距离比直接i-&gt;j要短的话，更新一下dist的距离和path的路径 （特别注意：关于循环的顺序，k一定在最外层循环，不然程序会出现差错，以下为解释） k在最外层保证了每次k变动后会遍历图上所有的点以达成完备的更新。 1234567891011121314151617181920212223​void dist_init(int dist[N][N])&#123; freopen("SP_edge.txt","r",stdin); for(int i=0;i&lt;N;i++) for(int j=0;j&lt;N;j++) dist[i][j]=INT_MAX; int va,vb,cost; while(scanf("%d %d %d\n",&amp;va,&amp;vb,&amp;cost)==3) dist[va][vb] = cost; for(int i=0;i&lt;N;i++) dist[i][i] = 0;&#125;void path_init(int path[N][N])&#123; for(int i=0;i&lt;N;i++) for(int j=0;j&lt;N;j++) path[i][j]=i;&#125;void floyd(int dist[N][N],int path[N][N])&#123; for(int k=0;j&lt;N;j++)&#123; for(int i=0;i&lt;N;i++)&#123; for(int j=0;k&lt;N;k++)&#123; if(dist[i][k]+dist[k][j]&lt;dist[i][j]&amp;&amp;dist[i][k]!=INT_MAX&amp;&amp;dist[k][j]!=INT_MAX)&#123; dist[i][j]=dist[i][k]+dist[k][j];path[i][j]=k; &#125; &#125; &#125; &#125;&#125;​]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AVLtree]]></title>
    <url>%2F2018%2F12%2F08%2FAVLtree%2F</url>
    <content type="text"><![CDATA[平衡二叉搜索树(Self-balancing binary search tree)又被称为AVL树（有别于AVL算法）它左右的两个子树高度差的绝对值不超过1，且左右两个子树都是平衡二叉树。 引入：在说平衡二叉树之前，我们先需要谈谈二叉排序树，详见我之前在《排序》中所写。当排序树构建出来过于“畸形”，两边不对称，极端一点就是一路下来毫无分叉，那么显然，它的时间复杂度就是n，为了避免这种情况或者说，为了找寻最优情况，我们希望我们构建出来的二叉树可以两边对称平衡一下，使其树的深度为lonn而非n，为此，我们引入平衡二叉树的概念。 调整(旋转)：当每次插入一个结点后，我们根据这棵树的现状对它进行旋转操作，可以简单的分为： 单旋： 在A结点的左孩子的左子树或者右孩子的右子树上插入结点。 直接将B结点提上来，再把离A最近的子树滑给A。 双旋： 在A结点的左孩子的右子树或者右孩子的左子树上插入结点。 直接将C提到A、B之间，再把C的子树分别分给A、B所缺的位置。 删除：查找：现在平衡树中查找到关键字相同的结点p 删除：分以下几种情况： 叶结点：直接删除就好 单分支结点：把后面那个孩子结点接上来就好啦 双分支结点：把这个双分支结点p的值，用其中序前驱结点q的值替代后，直接删掉结点q]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tree]]></title>
    <url>%2F2018%2F12%2F08%2FTree%2F</url>
    <content type="text"><![CDATA[这里是关于二叉树的一系列函数C的代码二叉树的编程我觉着可以帮助你学习递归 : )123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;typedef int ElemType;typedef struct node&#123; ElemType data; struct node* lc; struct node* rc; int visit;//真的，如果不是这样写最方便，我也不想直接改掉TNode结构体orz &#125;TNode;typedef struct&#123; TNode** qu; int n; int front; int rear;&#125;Tqueue;TNode* tree_init();//树的初始化void preorder(TNode* tree); //递归遍历void tree_pre(TNode* tree); //非递归遍历void inorder(TNode* tree); void tree_in(TNode* tree); void postorder(TNode* tree); void tree_post(TNode* tree); void level_order(TNode* tree);//层次遍历int tree_nodes(TNode* tree);int tree_leaves(TNode* tree);int tree_depth(TNode* tree);int tree_level(TNode* tree,int x,int* j);//查找int tree_width(TNode* tree);Tqueue* queue_init(int n)&#123; Tqueue* queue = (Tqueue*)malloc(sizeof(Tqueue)); queue-&gt;qu = (TNode**)malloc(sizeof(TNode*)*n); queue-&gt;front = 0; queue-&gt;rear = 0; queue-&gt;n = n; return queue;&#125;int main()&#123; freopen("tree.txt","r",stdin); TNode* tree = tree_init(); preorder(tree);printf("\n");tree_pre(tree);printf("\n"); inorder(tree);printf("\n");tree_in(tree);printf("\n"); postorder(tree);printf("\n");tree_post(tree);printf("\n"); level_order(tree); printf("\nTree leaves: %d\tTree depth: %d\tTree nodes: %d",tree_leaves(tree),tree_depth(tree),tree_nodes(tree)); int num;tree_level(tree,'K',&amp;num);printf("\t'K': %d",num+1); printf("\tTree width: %d",tree_width(tree));&#125; TNode* tree_init()&#123; TNode* tree = (TNode*)malloc(sizeof(TNode)); if(tree==NULL)&#123; printf("tree_init:malloc error."); exit(0); &#125; ElemType a; scanf("%d",&amp;a); if(a==0) tree=NULL; else&#123; tree-&gt;data = a; tree-&gt;visit= 0; tree-&gt;lc = tree_init(); tree-&gt;rc = tree_init(); &#125; return tree; &#125;void preorder(TNode* tree)&#123; if(tree==NULL) return; else&#123; printf("%c ",tree-&gt;data); preorder(tree-&gt;lc); preorder(tree-&gt;rc); &#125;&#125;void tree_pre(TNode* tree)&#123; Tqueue* stack = queue_init(tree_nodes(tree));//假装这是初始化栈的函数 while((stack-&gt;rear!=0)||(tree!=NULL))&#123; if(tree!=NULL)&#123; stack-&gt;qu[stack-&gt;rear++] = tree; printf("%c ",tree-&gt;data); tree = tree-&gt;lc; &#125; else&#123; tree = stack-&gt;qu[--stack-&gt;rear]; tree = tree-&gt;rc; &#125; &#125; free(stack);&#125; void inorder(TNode* tree)&#123; if(tree==NULL) return; else&#123; inorder(tree-&gt;lc); printf("%c ",tree-&gt;data); inorder(tree-&gt;rc); &#125;&#125;void tree_in(TNode* tree)&#123; Tqueue* stack = queue_init(tree_nodes(tree)); while((stack-&gt;rear!=0)||(tree!=NULL))&#123; if(tree!=NULL)&#123; stack-&gt;qu[stack-&gt;rear++] = tree; tree = tree-&gt;lc; &#125; else&#123; tree = stack-&gt;qu[--stack-&gt;rear]; printf("%c ",tree-&gt;data); tree = tree-&gt;rc; &#125; &#125; free(stack);&#125; void postorder(TNode* tree)&#123; if(tree==NULL) return; else&#123; postorder(tree-&gt;lc); postorder(tree-&gt;rc); printf("%c ",tree-&gt;data); &#125;&#125;void tree_post(TNode* tree)&#123; Tqueue* stack = queue_init(tree_nodes(tree)); while((stack-&gt;rear!=0)||(tree!=NULL))&#123; if(tree!=NULL)&#123; if(tree-&gt;visit==0) stack-&gt;qu[stack-&gt;rear++] = tree; tree = tree-&gt;lc; &#125; else&#123; tree = stack-&gt;qu[--stack-&gt;rear]; if(tree-&gt;visit==1) printf("%c ",tree-&gt;data); else&#123; tree-&gt;visit = 1; stack-&gt;qu[stack-&gt;rear++] = tree; &#125; tree = tree-&gt;rc; &#125; &#125; free(stack);&#125; void level_order(TNode* tree)&#123; Tqueue* queue = queue_init(tree_nodes(tree)); queue-&gt;qu[queue-&gt;rear++%queue-&gt;n] = tree; while(queue-&gt;front%queue-&gt;n!=queue-&gt;rear%queue-&gt;n)&#123; if(queue-&gt;qu[(queue-&gt;front)%queue-&gt;n]-&gt;lc!=NULL) queue-&gt;qu[queue-&gt;rear++%queue-&gt;n] = queue-&gt;qu[(queue-&gt;front)%queue-&gt;n]-&gt;lc; if(queue-&gt;qu[(queue-&gt;front)%queue-&gt;n]-&gt;rc!=NULL) queue-&gt;qu[queue-&gt;rear++%queue-&gt;n] = queue-&gt;qu[(queue-&gt;front)%queue-&gt;n]-&gt;rc; printf("%c ",queue-&gt;qu[(queue-&gt;front++)%queue-&gt;n]-&gt;data); &#125; free(queue);&#125;int tree_nodes(TNode* tree)&#123; if(tree==NULL) return 0; int a,b; a = tree_nodes(tree-&gt;lc); b = tree_nodes(tree-&gt;rc); return a+b+1;&#125;int tree_leaves(TNode* tree)&#123; if(tree==NULL) return 0; if(tree-&gt;lc==NULL&amp;&amp;tree-&gt;rc==NULL) return 1; return tree_leaves(tree-&gt;lc)+tree_leaves(tree-&gt;rc);&#125;int tree_depth(TNode* tree)&#123; int dl = 0; int dr = 0; if(tree==NULL) return 0; if(tree-&gt;lc==NULL&amp;&amp;tree-&gt;rc==NULL) return 1; dl = tree_depth(tree-&gt;lc); dr = tree_depth(tree-&gt;rc); return 1+((dl&gt;dr)?dl:dr);&#125;int tree_level(TNode* tree,int x,int *j)&#123; if(tree==NULL) return -1; // 没找到 返回-1； if(tree-&gt;data==x) return *j; int t=++*j; // 层数加1 int ret=tree_level(tree-&gt;lc,x,j); if(ret&gt;0)return ret; //在左子树分支找到 *j=t; //恢复层数 return tree_level(tree-&gt;rc,x,j);&#125;int tree_width(TNode* tree)&#123; if(tree==NULL) return 0; Tqueue* queue = queue_init(tree_nodes(tree)); queue-&gt;qu[queue-&gt;rear++%queue-&gt;n] = tree; int width=1; while(true)&#123; int size=queue-&gt;rear-queue-&gt;front;//当前层的节点数 if(size&gt;width) width = size; if(size==0) break; while(size&gt;0)&#123;//如果当前层还有节点就进行下去 TNode* node = queue-&gt;qu[(queue-&gt;front++)%queue-&gt;n];size--; if(node-&gt;lc) queue-&gt;qu[queue-&gt;rear++%queue-&gt;n] = node-&gt;lc; if(node-&gt;rc) queue-&gt;qu[queue-&gt;rear++%queue-&gt;n] = node-&gt;rc; &#125; &#125; free(queue); return width;&#125;​]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huffman Tree]]></title>
    <url>%2F2018%2F12%2F08%2FHuffman%2F</url>
    <content type="text"><![CDATA[哈夫曼树也称为最优二叉树，是一种带权路径长度最短的完全二叉树。最经典的用法就是做无损数据压缩的huffman coding 概念：哈夫曼树也称为最优二叉树，是一种带权路径长度最短的完全二叉树（Complete Binary Tree）树的带权路径长度：树中所有的叶结点的权值乘上其深度（到根结点的路径长度），然后进行加和的结果。哈夫曼树中根结点为第0层，N个权值构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为其层数。树的路径长度是从树根到每一结点的路径长度之和，记为WPL 易证哈夫曼树的WPL是最小的。 原理：编码表是通过对源符号出现的概率进行评估的方式得到，出现概率高的符号使用较短的编码，反之则使用较长的编码，由此实现编码后字符串的平均长度的期望值降低，从而达到无损压缩数据的目的。 举例：根据文本文件得出45个不同字符，通过所给的函数初始化哈夫曼树，根据45个初始节点完善填充整个（2*n-1 = 89）哈夫曼数组，再根据哈夫曼数组制作密码本，进行文件的压缩（加密）与解压（解密）的功能实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209​#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#define LEN 100typedef struct&#123; char ch; int weight;int parent; int lchild;int rchild;&#125;TNode;typedef struct&#123; char ch; char code[LEN];&#125;TCode;typedef struct&#123; char ch; int weight;&#125;TW;void select_subtree(TNode* pht,int n,int* pa,int* pb)&#123; for(int i=0;i&lt;n;i++)&#123; if(pht[i].parent==-1)&#123; *pa = i; break; &#125; &#125; for(int j=*pa+1;j&lt;n;j++)&#123; if(pht[j].parent==-1)&#123; *pb = j; break; &#125; &#125; //printf("\n%d\t%d\t%d\t%d\t",*pa,*pb,pht[*pa].parent,pht[*pb].parent); int temp = *pa; *pa = (pht[*pa].weight&gt;pht[*pb].weight)?*pb:*pa; *pb = (pht[*pb].weight&lt;pht[temp].weight)?temp:*pb; //printf("\n%d\t%d",*pa,*pb); for(int i=0;i&lt;n;i++)&#123; if(pht[i].parent==-1)&#123; if(pht[i].weight &lt; pht[*pa].weight&amp;&amp;i!=*pa&amp;&amp;i!=*pb) &#123;*pb = *pa;*pa = i;&#125; else if(pht[i].weight &lt; pht[*pb].weight&amp;&amp;i!=*pa&amp;&amp;i!=*pb) &#123;*pb = i;&#125; &#125; &#125; //printf("\n%d\t%d",*pa,*pb); &#125;TNode* create_htree(TW weights[],int n)&#123; TNode* pht = (TNode*)malloc(sizeof(TNode)*(2*n-1)); for(int i=0;i&lt;n*2-1;i++)&#123; pht[i].ch = (i&lt;n)?weights[i].ch:' '; pht[i].weight = (i&lt;n)?weights[i].weight:0; pht[i].parent = -1; pht[i].lchild = -1;pht[i].rchild = -1; &#125; int pa,pb; for(int i=n;i&lt;n*2-1;i++)&#123; select_subtree(pht,i,&amp;pa,&amp;pb); pht[pa].parent=i;pht[pb].parent=i; pht[i].lchild = pa;pht[i].rchild = pb; pht[i].weight = pht[pa].weight+pht[pb].weight; //printf("\n%d\t%02d\t%02d\t%02d\t%02d\n",i,pht[i].weight,pht[i].parent,pht[i].lchild,pht[i].rchild); //printf("%d\t%d\n",pht[pht[i].lchild].parent,pht[pht[i].rchild].parent); &#125; return pht;&#125;void encoding(TNode* pht,TCode book[],int n)&#123; char* str = (char*)malloc(n+1); str[n] = '\0'; for(int i=0;i&lt;n;i++)&#123; int idx = i;int j = n; while(pht[idx].parent!=-1)&#123; if(pht[pht[idx].parent].lchild==idx)&#123; j--;str[j]='0'; &#125; if(pht[pht[idx].parent].rchild==idx)&#123; j--;str[j]='1'; &#125; idx = pht[idx].parent; &#125; book[i].ch = pht[i].ch; strcpy(book[i].code,&amp;str[j]); printf("%c : ",book[i].ch); puts(book[i].code); &#125;&#125;void decoding(TNode* pht,char codes[],int n)&#123; freopen("your_love.txt","w",stdout); int i=0,p = 2*n-2; while(codes[i]!='\0')&#123; while(pht[p].lchild!=-1&amp;&amp;pht[p].rchild!=-1)&#123; if(codes[i]=='0') p = pht[p].lchild; else p = pht[p].rchild; i++; &#125; printf("%c",pht[p].ch); p = 2*n-2; &#125; printf("\n"); fclose(stdout); &#125;// 统计字符串text中字符出现的频率，参数n为字符串长度// 返回值为：text中出现的不同种类的字符个数// 副作用：通过指针参数间接返回两个数组，其中：// dict：字符数组，存放 text中出现的不同种类的字符// freq：整型数组，存放 text中出现的不同种类的字符的出现频率 int calc_freq(char text[], int **freq, char **dict, int n)&#123; int i, k, nchar = 0; int * pwght; char * pch; int tokens[256] = &#123;0&#125;; // 根据输入的文本字符串逐一统计字符出现的频率 for(i = 0; i &lt; n; ++i)&#123; tokens[text[i]]++; &#125; // 统计共有多少个相异的字符出现在文本串中 for(i = 0; i &lt; 256; i++)&#123; if( tokens[i] &gt; 0 )&#123; nchar++; &#125; &#125; // 为权重数组分配空间 pwght = (int*)malloc(sizeof(int)*nchar); if( !pwght )&#123; printf("为权重数组分配空间失败！\n"); exit(0); &#125; // 为字符数组（字典）分配空间 pch = (char *)malloc(sizeof(char)*nchar); if( !pch )&#123; printf("为字符数组（字典）分配空间失败！\n"); exit(0); &#125; k = 0; for(i = 0; i &lt; 256; ++i)&#123; if( tokens[i] &gt; 0 )&#123; pwght[k] = tokens[i]; pch[k] = (char)i; //强制类型转换 k++; &#125; &#125; *freq = pwght; *dict = pch; return nchar;&#125; int main()&#123; freopen("love_letter.txt","r",stdin); char* str = (char*)malloc(2000); gets(str); fclose(stdin); int** ch_f = (int**)malloc(4); char**ch_c = (char**)malloc(4); int n = calc_freq(str,ch_f,ch_c,strlen(str)); free(str); TW weights[n]; for(int i=0;i&lt;n;i++)&#123; weights[i].weight = (*ch_f)[i]; weights[i].ch = (*ch_c)[i]; &#125; free(ch_f);free(ch_c); TNode* pht = create_htree(weights,n); TCode codebook[n]; encoding(pht,codebook,n); freopen("love_letter.txt","r",stdin); char* word = (char*)malloc(2000); gets(word); fclose(stdin); freopen("codebook.txt","w",stdout); while(*word!='\0')&#123; for(int i=0;i&lt;n;i++)&#123; if(*word==codebook[i].ch)&#123; for(int j=0;j&lt;strlen(codebook[i].code);j++)&#123; printf("%c",codebook[i].code[j]); &#125; &#125; &#125; word++; &#125; fclose(stdout); //free(word); freopen("codebook.txt","r",stdin); char* codes = (char*)malloc(6000); gets(codes); fclose(stdin); decoding(pht,codes,n); return 0;&#125;​]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KMP]]></title>
    <url>%2F2018%2F12%2F08%2FKMP%2F</url>
    <content type="text"><![CDATA[普通的查找匹配需要在失配时回溯到失配串第二位继续开始查找是否匹配，复杂度过高。于是我们想着能不能一次不回头的走到底，针对模式串创建了一个辅助数组（next数组）next数组各个元的值：固定字符串的最长真前缀（第一个字符伊始，但不含最后一个）和最长真后缀相同的长度，以下举例。 n e x t 数 组 各元固定字符串 相同最长前后缀 前后缀相同长度 n e x t [0] a “ ” 0 n e x t [1] ab “ ” 0 n e x t [2] aba “a” 1 n e x t [3] abab “ab” 2 n e x t [4] ababa “aba” 3 n e x t [5] ababab “abab” 4 n e x t [6] abababc “ ” 0 n e x t [7] abababca “a” 1 a b a b a b c a 的 n e x t 数 组 为 ： -1 0 0 1 2 3 4 0 1 因为你的目标串没有必要完全回溯，可以把前面相同的位置掠过，因此有了基于next数组的KMP算法，以下举例： 目标串T：ababaacababbabababca 模式串P：abababca 指针i指向目标串，指针j指向模式串，if（T[i]==P[j]）//匹配成功 i++ , j++//往后继续尝试是否匹配 如果失配，i指针不回溯，j指针回溯（j = next[j]），当回溯到首元时，无法再回溯，继续往后试探 i++ , j++ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748​#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;typedef struct&#123; char *pch; int len;&#125;Tstr;int* KMP(Tstr* T,Tstr* P,int *next)&#123; int i=0,j=0,k=0,m = T-&gt;len,n = P-&gt;len; int num[m]; for(int i=0;i&lt;m;i++) num[i]=0; while(i&lt;=m-n)&#123; //不超过目标串的长度，且i&gt;m-n时不可能存在匹配 while(j==-1||(j&lt;n&amp;&amp;T-&gt;pch[i]==P-&gt;pch[j]))&#123; //只要相同且不超过模式串长度就继续往前走 i++; j++; &#125; if(j==n) num[k++] = (i-n+1);//成功找到一个匹配 j = next[j];//通过next数组回溯模式串，继续寻找匹配 &#125; return num;&#125;int* KMP_next(Tstr* P)&#123; int *next = (int*)malloc(sizeof(int)*(P-&gt;len)); int j=0,k=-1,n = P-&gt;len; next[0] = -1; while(j&lt;n)&#123; if(k==-1||P-&gt;pch[j]==P-&gt;pch[k])&#123; next[j+1] = k+1; j++; k++; &#125; else k = next[k]; &#125; return next; &#125;int* KMP_nextval(Tstr* P)&#123; int* nextval = KMP_next(P); for(int j=1;j&lt;P-&gt;len;j++)&#123; if(P-&gt;pch[j]==P-&gt;pch[nextval[j]]) nextval[j]=nextval[nextval[j]]; &#125; return nextval;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>大一</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[方寸间的茶，骨子里的美]]></title>
    <url>%2F2018%2F04%2F24%2FHello%2F</url>
    <content type="text"><![CDATA[喜欢，从来都是简单随性的，它可能是雨天里脚踏在水坑上清脆的回响和扬起奇妙弧度的水花；也可能是夏日里偶然撞见的白色衬衫和“刺啦”一声打开的汽水罐……这些，是生活在这青葱岁月的我们所定义的喜欢，而在唐宋元明清，一扇又一扇翩跹舞开的帘幕下藏着的，是那个时代的人们心底最敏感、最柔软却又最热烈的喜欢——诗词。便如茶，元稹的“铫煎黄蕊色，婉转曲尘花”是喜欢；高鹗的“瓦铫煮春雪，淡香生古瓷”是喜欢；刘禹锡的“骤雨松声入鼎来，白云满碗花徘徊”是喜欢。每个人的喜欢都是不同的，一千种茶，在品茶者眼里是一千种人生、一千种欢喜。这接下来，我就借用朱海燕老师在《中国茶美学研究》里的一篇文章——《唐宋诗词中茶之“美”的刻画》，浅述一下我个人对于“茶”与“美”的认知与看法，以及流淌在诗词中的那一份微醉的喜欢。 茶形色之美 细如粟粒柔如蕊,肥如云腴壮似笋——茶芽之美 枪旗鸟爪劲姿爽,鹰嘴雀舌展芽叶——芽梢之美 圆如皓月润似玉,方比珪璧芳胜兰——团饼茶之美 茶芽，刚吐露的嫩芽无处不炫耀着她娇嫩诱人的初生姿态，这理当是茶这一植株在其生长的一生中最欢愉最激情向上的阶段，这个阶段表现最突出的便是生命力——那种绿的逼人的翠色，让人生怕它会在你转身的那一刹那“噗啦”一声滴下来，令你不得不着迷似的定在那里，移不开视线。而作为人类文明演变发展的长河中，思绪最为敏感的那一圈人中，在我国唐宋时期，体现的最为明显的便是或风花雪月，或忧国忧民的诗人。他们用他们传世的诗、词、曲勾画着他们当时心底那份敏感纯粹被挑拨得激动不已的时刻。这是个感性的区域，从来就没有个方程中唯一解这样让人觉着安稳，却不禁扫兴的说法。每个人在那一瞬所呈现的感觉是不一样的，同时也是最能展示和区分他们波澜壮阔的内心世界的东西，那就是——想象。想象，这是自人类出生开始就赐予人一生的珍贵的天赋：它是天生的，孩子的想象往往最为干净纯粹，包含了最初始最接近“0”的美好烂漫，而随着世俗的沾染，想象这种东西渐渐被束缚，被怀疑，被丢弃……我个人，或者说，在我这个时期，刚感受着离家两千公里的大一生活的我，愈发地觉得，失去了想象的人，是最为可悲的，因为这应是一个不可逆的过程。但是在这个社会转型的大过渡时期，一个大弯甩过来，荡平了多少人纯真，不切实际却美好异常的想象；甩掉多少人那心底小小的仅存的遵守和天真；一个弯所圈出来的怀疑与自我否定，与其说是辩证性地思考，倒不如说是失去自信地辩解。当桌上的茶叶全部被速溶咖啡取代的时候，不敢说这种前进我能有多讨厌，但我敢说我绝不会喜欢。我更希望的是另一种前进，一种精神上或者说人性上的前进，给我的不再是昂不起的头颅和直不起的脊梁的感觉，不再是没有自信没有底气却还要不断争辩的无力与腻歪，而是一种像茶芽一般喷涌着惊人生命力的饱满姿态，那种骨子里的自信、自知与谦和，真正做到心细如粟，心柔如蕊；神壮似笋，肥如云腴。同时，想象也是后天所培育发展的，一个人所能想象出的事物，起源于这个人从他出生至今所经历的事情，所感悟的美好，所体会的失落，所思考的问题，所接触的人群，所读过的书籍……这一切的一切所综合起来构成了他想象的基石。所以在那个信息不流通的年代，他们游山玩水，他们体验人生；他们“不羡朝入省”，他们“不羡慕登台”；他们感悟不同的风土人情，他们把玩不同的文物古籍；这样的他们用他们一生的所见所闻，所思所感筑成了这座瑰丽的想象宫殿，供我们观赏感叹，找寻在快节奏下的闹市里心灵的一片净土，甚至说是归宿。 接下来，就是两种不同方向的意象美，芽梢和团饼茶。芽梢较尖，一般所代表的是一种灵动的个性；而饼茶较为圆润，讲究的是一种温润的淳善。 枪旗、鸟爪、鹰嘴、雀舌，古人对芽梢的形容无一不将浓郁的生命力赋给了这小巧的尖角，擦亮了一抹惊艳的生命色彩。明明只有两字，却极鲜明地将芽梢的那种“尖”劲儿脆生生地呈现在我们的眼中，茶叶本身的形状只是种客观存在的形态，并不包含融在这两个字里的“灵魂”，无疑，这迸发出强烈生机与共鸣的感受源于诗人自身的灵魂，在诗人的一字一句中，融入了他对于这个世界自然而又感性的认识，每一种感性的认知都单纯而又坦诚地给读者打开了一扇了解作者根源的门，他幼年的纯真或残酷，他少年的幻想或青涩，他成年的欢愉或失落，构成了他对这个自然世界的认知，一字一句中我们都能看见掠过的只属于他的浮窗剪影。由此，在我个人看来，感性的或者说个性的创作是会流传不朽，待人发现的。这样的创作会勾起读者的情绪与回忆，人只有对自己共鸣的作品才会真正的爱不释手，产生一种微妙的专有感与占有欲，先不论对错与后续的影响，但是这个作品无疑会因为这样微妙的感情而传递下去。而这之中传承的不仅是茶叶神态中的神韵，更有一种流淌在华夏血脉里，刻进骨子里的精神，如茶一般，千姿百态，各有各的个性与傲骨。 “圆如皓月润似玉,方比珪璧芳胜兰”，说来这和前两种有着本质上的区别。前两种是茶自然的、原生态的情况，如果说这前两种是原汁原味的生命力的展现，那么，团饼茶就是体现我们中华先辈劳动智慧与蕙质兰心的引喻了。若是按我的想象来看，这团饼茶所代表的，就是古人对“君子”的美好向往与期待了：“圆如皓月润似玉”，象征着君子的温润如玉，包容沉稳；而“方比珪璧芳胜兰”，则象征着君子的清远宁人，秀智兰香。在朱海燕女士的原文中有提到：“形色产生美感其根源是人类在社会实践时对自然形状(包括运动、结构)的把握和运用的过程中，使形色与主体知觉结构的相互适应，从而引起审美愉悦。品读茶诗时，可以感受诗人们对茶形色的审美情趣，而形象的刻画更能激发人们无尽的遐想：麦粒的纤小，枪旗的英姿，雀舌的灵巧，琼蕊的秀丽，圭璧的圆润，紫的高贵、绿的生机、白的纯洁、黄的温馨、黑的凝重，每个意象仿佛就是一幅精妙绝伦的工笔画。”可以说，在茶的形色之美上，古人的诗词将自己的美好祝愿与自身情感全部寓情于“茶”，在品茶的形色中感受诗词的妙韵，在品读诗词中欣赏着茶的形色，将声色与想象融于美之中，清幽的茶与沉香的诗，相互交织构成了现在我们所品味研究的“茶美学”。 茶香之美 香飘九畹清若兰,幽薄芳草得天真——茶香之清幽美 疏香皓齿有余味,更觉鹤心通杳冥——茶香之悠远美 风流气味未染尘,不是人间香味色——茶香之脱俗美 “茶的香气,分为真香和混和香两种,真香是茶自身所具有的香味,混和香是加入香味物与茶的真香混合而形成。不同的茶香各有区别,或甜润馥郁,或清幽淡雅,或高爽持久,或鲜灵沁心,因茶之别而变化无穷。” 著名茶叶专家施兆鹏在其主编的《茶叶审评与检验》一书中，将成品茶香气归纳为九种香气类型：毫香型、嫩香型、花香型、果香型、清香型、甜香型、火香型、陈醇香型、松烟香型。正是因为这些纷繁的香气，些微的不同往往会带给品茶者全然不同的崭新感受，这也是茶香的无穷魅力所在，引起文人墨客的争相赞颂。而除此之外，诗人当时所处的环境和心境对茶香的品味也有很大的影响，想来，吵杂市井里的茶香和幽静庭院里的茶香，给人的感受是绝对不同的。“花笺茗碗香千载，云影波光活一楼”茶香是一个很玄妙的东西，用嗅觉触发想象，便比“形色”来得更为飘忽。 唐代诗人李德裕描写茶香为：“松花飘鼎泛，兰气入瓯轻”。“轻”字形象地表达如兰花般极为清雅的茶香随着茶的烹煮而逐渐散发出来的过程。“香于九畹芳兰气”，茶香清幽如兰，不浓烈，不艳俗，香虽清淡却能随风飘送至数里之外，如此清风傲骨的象征，又有哪一个文人雅士能不受她的诱惑?在我家乡有种被称作“汀溪兰香”的茶叶，因为在生长过程中长期与空谷幽兰相伴随生长，便渐渐浸染上了兰花的那一股幽香，颇受一些文人雅士所推崇，当然也因此这种茶叶的珍品售价极高。先不论其他，就单单这一点便不难看出品茗者们对于兰香是何等的推崇，大概都是向往着《离骚》中“余既滋兰之九畹兮，又树蕙之百亩”生活的吧。 朱海燕老师在原文中所引用的这句“疏香皓齿有余味，更觉鹤心通杳冥”，取自于温庭筠的《西陵道士茶歌》，原诗这样写道： 乳窦溅溅通石脉，绿尘愁草春江色。 涧花入井水味香，山月当人松影直。仙翁白扇霜鸟翎，拂坛夜读黄庭经。 疏香皓齿有余味，更觉鹤心通杳冥。 茶香悠远，这份悠远如烟般萦绕在诗人温庭筠的皓齿舌尖，逐渐在精神上更加地贴近一种通明的无为而治的感觉，在诗人主观上与心中所念的“道”相为贴近。按照我个人的理解，“道法自然”，道修的是自身与自然的连接，并不主张用世间的条条框框来束缚自己。他们的随性而为，他们的无为而治，不是说随意、无节制地放出自身的欲望破坏人常纲理，他们的心不是随意散乱的，而更偏向于一种浑圆透彻的状态，在我个人的想象中，便是种“太极”的姿态，周而往返、浑圆剔透。他们所修的是一种智慧的自然，他们去探寻自然而不改变自然，故因此，与自然更加亲近。这或许也是为什么道家和儒家一样推崇着茶道，甚至有着“以茶入道”的说法与故事。也不知道是茶本身就如此玄妙，还是在人为赋予自身的幻想与寄托之后，才那么地令人着迷。但不管怎样，茶，早已成为我国传统文化一面无可或缺的明镜，映照着华夏五千年的历史变迁与文化发展。 茶味之美 流华无尘净肌骨,疏瀹清味涤心源——茶味之清美 琼蕊甘露贵流霞,灵芽云液胜醍醐——茶味之甘美 茗饮醇滑齿颊香,消尽酲醲爽气来——茶味之爽美 香茗一盏甘与苦,人生百味寓其中——“味外之味” “清”，这个在中国古代美学上留下浓墨重彩的一笔的字。“清”字，《说文解字》之中将其释为“澄水之貌”，意指水澄澈明净的样子。茶味之清，体现于淡。这种淡不是苍白的寡淡，而是“清淡”与“轻淡”。借用朱海燕老师在《中国茶美学研究》中所说，“其味觉是丰富的，味感是微妙的”。我们为了感受清美不妨设想一下，说到清，想到了什么？清雨？这个词最先映入我的脑海，接着便是随之而来的意想。清雨？为什么不是微雨？“落花人独立，微雨燕双飞”第一眼见到小山的词，便觉惊艳，不是李商隐那般华美的惊艳，而是扑面而来的清爽与干净利索。但微雨成丝，连绵不绝，与心中所期待的清美相比，总觉着是差了些味道。不知为何，说到“清雨”，总会有花浮现，大概是那句“清明时节雨纷纷”在脑中洗脑般的刻印所致。“清明时节雨纷纷”的清雨，是带着踏青的美好与春日的生机的。或者说，是带着我对于春雨踏青的印象。在玉珠连丝的春日，伴着雨线划过脸颊的清凉，看着雨水洗过的绿色，陷在其中的我大概分不出到底是“青”还是“清”，但这里的一切和我脑海中浮现的一切，一定都是“美”的概念作为我内心里的某种具象化。 “甘”这一点自不必说，想来在大家心中甜美都是很幸福很美好的存在。而对于茶叶而言，茶味之甘美却又与我们正常情况下所提及的甘美不同，我们在日常生活中喜爱甜食，用化学的眼光来看待是因为甜食中的糖分在于人体接触后发生化学变化造成大量的多巴胺，通过不断的吸收与溶解，多巴胺通过血管流至全身，最后刺激神经致使人体产生亢奋状态，这可能也是我对巧克力那么痴迷的原因之一吧。而茶味的甘美是在于它的回味，先苦后甜，而这种苦后回甘之味才是受古代文人雅士所推崇的，这倒也符合我们中国传统的文化思想观念与美德。“爽”，这里的爽同样和我们现在常说的有些区别，这里所表示的更多是“神清气爽”，现在我们也常听到长辈们说关于醒酒茶的功效，虽然现代科学证明了用茶醒酒是错误的做法，但这也是古代人将茶作为提神醒脑的良药的佐证。按文中所说便是“好茶往往滋味醇爽，入口润滑而不紧涩，饮过之后齿颊留香，提神醒脑，畅意不已，唐宋时任将这种让人通体舒泰的美感谓之‘爽’”。而所谓“味外之味”，简单来说就是借品茶来品味人生。比如苏轼一生坎坷，在“乌台诗案”之后，在儒、道、佛思想的共同影响之下，有着复杂的处事观念，既有儒家忧国忧民的入世之心，又有佛家放空自我的出世之心，同时又在道家的影响下向往自然，寻求与自然的超脱。这三种思想集中在一个人身上，不由显得矛盾而又分裂。为了调和改善这种情况，他把品茶作为沟通自然、内省自性、品味人生、超越自我的载体，将不同的思想通过“茶”这一纽带相互串连。也因如此，茶渐渐成为了他生命中寄思不可缺少的物品。这便是茶之“味”，茶之美的某种体现吧。 茶叶，在唐宋词人的眼中，是寓于自身丰沛情感的寄托，是自己内心世界的写照。茶如明镜，一滴茶水滴落下去，“叮”地激起一圈水纹，荡起一层清绿，随之平静无褶。诗人走到茶水边，先看上那么几眼，看看茶水中荡漾的自己的“形色”，然后不用动上鼻尖，便会闻到自心里溢出来的“茶香”，接着便一头栽进这茶水里，让茶水洗涤着自己的身子和心，去体会最回归与最纯粹的“茶味”，纯粹到令人艳羡。这些，便构成了唐宋诗词中对于“茶”之美的刻画。而这些美，是需要寻着诗词品赏茶、感受茶，将茶带进自己的人生与思考才能真正体会到的美学。希望看到这篇文章的人，都能尝试着去体会中国的茶文化，去感悟这之中蕴藏着的茶美学。]]></content>
      <categories>
        <category>随记</category>
      </categories>
      <tags>
        <tag>大一</tag>
        <tag>茶美学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深夜]]></title>
    <url>%2F2018%2F02%2F20%2F%E9%9A%8F%E7%AC%94%2F</url>
    <content type="text"><![CDATA[不知道现在的自己所思考的究竟和以前的自己所想的有多少出入。也不知道现在自己所坚持的和以前的自己有多少区别。能做的，只有坚信着未来不断前进。未来是一个闪着光的字眼，闪着一种叫希望的光。怀着希望是最悲伤的事情，因为希望，所以要不断支撑着自己向前爬行。怀着希望是最幸福的事情，因为希望，所以赌上一切只是为了几近虚妄的“光明的未来”。仿佛抓住了那片幻想中的光明，就能得到救赎，可以宽恕一切不希望发生的过去，或者说，给那些过去安排了一个合适到完美的理由。但是每个人心底都清楚得很，光，哪是人可以抓住的？于是乎，又给了自己一个超脱“人”这个范畴的动机与理由。直到最终面目全非，披着“人”的幌子留给光鲜而已。]]></content>
      <categories>
        <category>随记</category>
      </categories>
      <tags>
        <tag>大一</tag>
        <tag>随记</tag>
      </tags>
  </entry>
</search>
